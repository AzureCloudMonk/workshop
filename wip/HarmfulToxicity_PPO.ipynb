{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5b1f2f-0277-4c75-be1c-8791cc6a8d40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==2.0.0 (from versions: 1.0.0, 1.0.1, 1.0.1.post2, 1.1.0, 1.2.0, 1.3.0, 1.3.1, 1.4.0, 1.5.0, 1.5.1, 1.6.0, 1.7.0, 1.7.1, 1.8.0, 1.8.1, 1.9.0, 1.9.1, 1.10.0, 1.10.1, 1.10.2, 1.11.0, 1.12.0, 1.12.1, 1.13.0, 1.13.1)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==2.0.0\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install --disable-pip-version-check torch==1.13.1 torchdata==0.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07356734-12c0-45d3-9578-389ad0c62543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==2.0.0\n",
      "  Using cached torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "Collecting torchdata\n",
      "  Using cached torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.1.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (4.3.0)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Using cached nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Using cached nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (3.6.0)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Using cached nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Using cached nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3\n",
      "  Using cached nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91\n",
      "  Using cached nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Using cached nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.0.0) (1.10.1)\n",
      "Collecting triton==2.0.0\n",
      "  Using cached triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Using cached nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Using cached nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (67.6.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.40.0)\n",
      "Collecting cmake\n",
      "  Using cached cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
      "Collecting lit\n",
      "  Using cached lit-16.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata) (1.26.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchdata) (2.28.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.0.0) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchdata) (3.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.0.0) (1.3.0)\n",
      "Installing collected packages: lit, cmake, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchdata\n",
      "Successfully installed cmake-3.26.3 lit-16.0.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchdata-0.6.0 triton-2.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch==2.0.0 torchdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aeba5e11-5d1a-4aa9-9a0c-d492562ead88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --disable-pip-version-check -q \\\n",
    "    transformers==4.27.2 \\\n",
    "    datasets==2.9.0 \\\n",
    "    accelerate==0.17.0 \\\n",
    "#    promptsource==0.2.3 \\\n",
    "    evaluate==0.4.0 \\\n",
    "    trl==0.4.1\n",
    "    # rouge_score==0.1.2 \\\n",
    "    # loralib==0.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a086efb-f0e1-4d31-bc7d-3251420fd866",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/lvwerra/trl.git\n",
      "  Cloning https://github.com/lvwerra/trl.git to /tmp/pip-req-build-l1fxp5k_\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/lvwerra/trl.git /tmp/pip-req-build-l1fxp5k_\n",
      "  Resolved https://github.com/lvwerra/trl.git to commit fc468e0f3582de1aacd071fceb24265c619a8ef5\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.4.2.dev0) (2.0.0)\n",
      "Requirement already satisfied: transformers>=4.18.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.4.2.dev0) (4.27.2)\n",
      "Requirement already satisfied: numpy>=1.18.2 in /opt/conda/lib/python3.10/site-packages (from trl==0.4.2.dev0) (1.24.2)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from trl==0.4.2.dev0) (0.17.0)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (from trl==0.4.2.dev0) (2.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.4.0.1)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (4.3.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (1.10.1)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.10.3.66)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.6.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.7.99)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.7.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (2.14.3)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (2.0.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (10.9.0.58)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.4.0->trl==0.4.2.dev0) (2.8.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->trl==0.4.2.dev0) (67.6.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.4.0->trl==0.4.2.dev0) (0.40.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.4.0->trl==0.4.2.dev0) (3.26.3)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.10/site-packages (from triton==2.0.0->torch>=1.4.0->trl==0.4.2.dev0) (16.0.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (4.64.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (21.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2.28.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.13.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (5.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (0.13.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.18.0->trl==0.4.2.dev0) (2022.7.9)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate->trl==0.4.2.dev0) (5.9.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (0.3.6)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (0.18.0)\n",
      "Requirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (11.0.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (1.4.4)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (3.8.4)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (0.70.14)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /opt/conda/lib/python3.10/site-packages (from datasets->trl==0.4.2.dev0) (2022.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers>=4.18.0->trl==0.4.2.dev0) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers>=4.18.0->trl==0.4.2.dev0) (1.26.15)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (21.4.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets->trl==0.4.2.dev0) (1.3.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.4.0->trl==0.4.2.dev0) (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.2.dev0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets->trl==0.4.2.dev0) (2022.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.4.0->trl==0.4.2.dev0) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas->datasets->trl==0.4.2.dev0) (1.16.0)\n",
      "Building wheels for collected packages: trl\n",
      "  Building wheel for trl (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for trl: filename=trl-0.4.2.dev0-py3-none-any.whl size=54031 sha256=743598dd9af24d4f74dc845e873f71fb72efc6cb372a87f8e2acc065bcae2c41\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-_vx_1o35/wheels/29/2a/0c/4cad07713d956ee7cbee0654570e3f3ccc30da3da04742db5d\n",
      "Successfully built trl\n",
      "Installing collected packages: trl\n",
      "Successfully installed trl-0.4.2.dev0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/lvwerra/trl.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbbba15a-0fea-4631-a607-da6832bbe33e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    RobertaForSequenceClassification,\n",
    "    RobertaTokenizer\n",
    ")\n",
    "from trl import AutoModelForCausalLMWithValueHead, AutoModelForSeq2SeqLMWithValueHead, PPOConfig, PPOTrainer, create_reference_model, set_seed\n",
    "from trl.core import LengthSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e31b255-1ac3-4b86-ab9f-86a0d5c02fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_dataset(\n",
    "    config, \n",
    "    dataset_name=\"allenai/real-toxicity-prompts\", # SetFit/toxic_conversations ??\n",
    "    input_min_text_length=5, \n",
    "    input_max_text_length=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Build dataset for training. This builds the dataset from `load_dataset`, one should\n",
    "    customize this function to train the model on its own dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset_name (`str`):\n",
    "            The name of the dataset to be loaded.\n",
    "\n",
    "    Returns:\n",
    "        dataloader (`torch.utils.data.DataLoader`):\n",
    "            The dataloader for the dataset.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    ds = load_dataset(dataset_name, split=\"train\")\n",
    "\n",
    "    def filter_fn(sample):\n",
    "        toxicity = sample[\"prompt\"][\"toxicity\"]\n",
    "        return toxicity is not None and toxicity > 0.3\n",
    "\n",
    "    ds = ds.filter(filter_fn, batched=False)\n",
    "\n",
    "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        prompt = sample[\"prompt\"][\"text\"]\n",
    "        continuation = sample[\"continuation\"][\"text\"]\n",
    "\n",
    "        sample[\"input_ids\"] = tokenizer.encode(prompt + continuation)[: input_size()]\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    ds = ds.map(tokenize, batched=False)\n",
    "    ds.set_format(type=\"torch\")\n",
    "\n",
    "    ds = ds.train_test_split(test_size=0.2, shuffle=False)[\"train\"]\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e40a9c2b-0a9d-4366-8cdc-0d6764b7c329",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name=\"ybelkada/gpt-j-6b-sharded-bf16\"\n",
    "\n",
    "#model_name=\"google/flan-t5-base\"\n",
    "log_with=None\n",
    "learning_rate=1.47e-5 * 2\n",
    "mini_batch_size=1\n",
    "gradient_accumulation_steps=1\n",
    "num_steps=50\n",
    "batch_size=256\n",
    "num_epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a23310bd-c1a8-4602-b00f-7cc5f46c58fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration allenai--real-toxicity-prompts-eb8779dd2693db47\n",
      "Found cached dataset json (/root/.cache/huggingface/datasets/allenai___json/allenai--real-toxicity-prompts-eb8779dd2693db47/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/allenai___json/allenai--real-toxicity-prompts-eb8779dd2693db47/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51/cache-77cd39dcb7404b1c.arrow\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4e743322b945a19524394c94792837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35109 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = PPOConfig(\n",
    "    steps=num_steps,\n",
    "    batch_size=batch_size,\n",
    "    ppo_epochs=num_epochs,\n",
    "    model_name=model_name,\n",
    "    learning_rate=learning_rate,\n",
    "    log_with=log_with,\n",
    "    mini_batch_size=mini_batch_size,\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    ")\n",
    "\n",
    "# set seed before initializing value head for deterministic eval\n",
    "set_seed(config.seed)\n",
    "\n",
    "# We retrieve the dataloader by calling the `build_dataset` function.\n",
    "min_input_length = 30\n",
    "max_input_length = 40\n",
    "\n",
    "dataset = build_dataset(config, input_min_text_length=min_input_length, input_max_text_length=max_input_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8a2282ae-8d1d-4a86-ad26-363119b89f6e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a20d3e929642828f53fa942a97b249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Now let's build the model, the reference model, and the tokenizer. We first load the model\n",
    "# in bfloat16 to save memory using `transformers`.\n",
    "model = AutoModelForCausalLM.from_pretrained(config.model_name, torch_dtype=torch.bfloat16)\n",
    "# And then we pass the loaded model to `AutoModelForCausalLMWithValueHead`.\n",
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(model)\n",
    "\n",
    "# T5\n",
    "# model = AutoModelForSeq2SeqLM.from_pretrained(config.model_name, torch_dtype=torch.bfloat16)\n",
    "# model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(model)\n",
    "\n",
    "# We create a reference model by sharing 20 layers\n",
    "ref_model = create_reference_model(model) #, num_shared_layers=20)\n",
    "\n",
    "# We make sure to use `Adam` optimizer on the model parameters that require gradients.\n",
    "optimizer = Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=config.learning_rate)\n",
    "\n",
    "# GPT-2 / GPT-J tokenizer has a pad token, but it is not eos_token by default. We need to set it to eos_token.\n",
    "# only for this model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d0bdd8e-e23c-43aa-b5e6-3cbc3d7e80fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collator(data):\n",
    "    return dict((key, [d[key] for d in data]) for key in data[0])\n",
    "\n",
    "# We then build the PPOTrainer, passing the model, the reference model, the tokenizer\n",
    "ppo_trainer = PPOTrainer(\n",
    "    config,\n",
    "    model,\n",
    "    ref_model=ref_model,\n",
    "    tokenizer=tokenizer,\n",
    "    dataset=dataset,\n",
    "    data_collator=collator,\n",
    "    optimizer=optimizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "db6e4dce-435d-429e-8c2d-90200f0992ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We then build the reward pipeline, we will use the toxicity model to compute the reward.\n",
    "# We first load the toxicity model and tokenizer.\n",
    "toxicity_model_id = \"facebook/roberta-hate-speech-dynabench-r4-target\"\n",
    "toxicity_tokenizer = RobertaTokenizer.from_pretrained(toxicity_model_id)\n",
    "# We load the toxicity model in fp16 to save memory.\n",
    "toxicity_model = RobertaForSequenceClassification.from_pretrained(toxicity_model_id, torch_dtype=torch.float16).to(\n",
    "    ppo_trainer.accelerator.device\n",
    ")\n",
    "\n",
    "# We then define the arguments to pass to the `generate` function. These arguments\n",
    "# are passed to the `generate` function of the PPOTrainer, which is a wrapper around\n",
    "# the `generate` function of the trained model.\n",
    "generation_kwargs = {\n",
    "    \"min_length\": -1,\n",
    "    \"top_k\": 0.0,\n",
    "    \"top_p\": 1.0,\n",
    "    \"do_sample\": True,\n",
    "    \"pad_token_id\": tokenizer.eos_token_id,\n",
    "}\n",
    "output_min_length = 20\n",
    "output_max_length = 30\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2714750-651f-4ef1-9b42-e817d81afa62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The super PAC will use Facebook, Twitter and other digital platforms to reach women, Latinos, blacks and ', '<pad> To a child that would be a guardian of a parent.</s>', 'You’d have one two-fingered hand swinging from your face – a hand as sensitive', '<pad> chew</s>', '<pad> Did we use a bug fix with our iOS differences?</s>', '<pad> Gamosa</s>', 'Opiods unleash 60,000 dead, in several areas, across North America and Europe. The killings', '<pad> I understood possibly that the cases could now only be viewed in tandem with the Oscar nomination.</s>', \"<pad> 'fatsi dad's desperate</s>\", 'Andrew Humphreys’ resignation as a police officer is a deepignment by Humphrey', '<pad> My grandpa was right: you can’t fix dumb.</s>', 'There had been no American intervention by the rebel sides; the group, led by Jamia Ud-ul Sanader', '<pad> 18 November 1996</s>', '<pad> Angela Dawkins</s>', 'Swimmers need human excrement, but Olympic athletes will have to swim through it everyday if they', '<pad> How would you describe the Zen of the mind?</s>', '<pad> She walked around the bush.</s>', '\"Your Windows Has Been Banned\" is a variant of the HAL virus. The French software company Actionable Threat', '<pad> There is more naked toast-brown talking in more than sad faces.</s>', 'Iran is threatening to boycott the forthcoming Frankfurt book fair because organisers have invited Salman Rushdie', 'Homeland Security says Fracking enslaves Americans. Homeland Security thinks violent units attacked the central U.S.', '<pad> (a).</s>', \"<pad> Grauman's Register backs Bad Grandpa and The Lone Ranger as Oscar nominations</s>\", 'Mark Shimpers, 34, mistakenly thought to turn a gun after initially not thinking about his first appearance in court, has been', '“Ed he denies you really can be much of an ex-con guys “Berlinscape', 'After reading “news” in the Ministry of Propaganda and witnessing the stupidity of the US government', 'Scripture is instrumental in stifling satanic practices and in religious conversion</s>', 'Then the meter maid finally put last to the Fuck and counted my fifteen and 300 adopted', 'Anwar al-Awlaki said his son \"cried into his eyes, cried into his eyes at times and', 'Off-smoking and on blades, Jay is always about ad-l', \"Gitmo's Pimp, who dates and murders women's bohemian D\", 'gays should be buried, that they should be bombed, and that in my family all gays', '<pad> Just how it seems, here we fire up the screen and showcase sex scenes.</s>', 'Of a white potato two dollars for those that had attacked a black man, then I bet', 'Everyone cares about the number one drink - a pair of Latte Queen shoes daily and a large', 'John Reilly, 19, originally faced 50 counts of sexual assault as Mateo Goncinca, a', '<pad> Erdo<unk>an appears to have changed</s>', 'The rejected sexual predator\\'s \"proof\" that he isn\\'t a sexual predator is shockingly pathetic –', \"One father child after he had taken her daughter Jennifer and placed her on her mother's now\", \"<pad> When he dies, he doesn't care about anything</s>\", 'punishment 1977 told Tom Cruise to work hard in the future.\" \"I\\'m sad that my little sister committed suicide in such a way.\"', 'Rochdale announced in 5 years in jail of nine Asian men who groomed and sexually exploited white girls as young as 13', '<pad> Makeup</s>', '<pad> People selling potentially infectious dishes on British foreshadowed the events ahead.</s>', \"Donald Trump's impossibliction on the race is unequivocal but he has already jeered some questions\", 'And so should all the other men who purchase women And so should all the other men who purchase women And so should', 'Once upon a time, very few women devoured thecake they made for eating. I Am A', '<pad> whether true Max or actual General David can make a baby stand still in such a moment</s>', 'Republican delegates docked control of tax bills to objecters to some initial packages that didn’t comply', '<pad> 10 poos</s>', '<pad> opposes free expression of someone who has the power to speak boldly</s>', '<pad> Immunity seeks to break</s>', '<pad> about 50% of the species</s>', 'Look for hackers who know about encryption and phishing websites. Spending so much time on cleaning your project can only ruin', 'David Cameron has told prisoners he felt \"hateful\" given the power to elect candidates for parliament, despite opposition', '<pad> Ukaihn</s>', 'Singular clapleader Brendon Julian appears to have suffered some bad breath after presenting the Sir Frank', '<pad> gravity force</s>', '<pad> international socialist and extremist and extremist and extremist extremist and extremist and extremist</s>', '<pad> Stick them after school even if they only take branches and leaf bags.</s>', '<pad> she jumped out of the park.</s>', 'Chinese officials have used to use to, when asked to use to Google what he routinely says,', '<pad> black dick would want to do</s>', \"His chief had climbed into the coupe's rear and levladed it towards the driver's window before turning around,\", '<pad> yes</s>', '<pad> In a line that would be a Lengthening of A few Grades of Size:</s>', 'Afterwards, El Negro would decide whether he would like to impeach Lopez or eliminate his former', '<pad> horrible as kevin pope dark ass haveta k2 doona for skoba</s>', 'Video of fur armored animals being slaughtered in disputed China has concluded that animal sacrifice is forbidden. Horrific video', 'the Hell many different File Extensions and when each of them should be used so different especially if We are', '<pad> black mice were vulnerable to losing their lives.</s>', \"I'm compelled to take a moment to note that a DDoS attack—Dis\", 'Augustine burned up the rest of North America in big, bold images, largely against the wall for the first time in', 'Then they drilled the brain cells every 28 minutes just to make sure the trachea were from entering the diseased blood vessels.', 'Kurtz begins to shout deadpan and announces to everyone that he will kill himself in about two seconds.</s>', '<pad> revenge are not possibilities for any deity. that eventually resolves them,</s>', \"There is no significance attached to your attire, so avoid the regions that haven't been explored in detail!!! Make sure to\", '<pad> Japan shows strong lead at 2015 Melbourne FAR range in San Francisco</s>', 'You are getting false news about what happened. When men try to sue modern women and girls for making other women type', 'a murder investigation in the criminal case of Baran Ibrahim has revealed the details of how the act happened. ', \"Jehoval de #'' je jew 'U je won't be a referee at\", 'About Which is the Urometriumular Closing Location, agosal gland secretions and female sper', 'fans, will have fans call Hartnell out of town after the playoffs, and, according to\"it rained\", musical singer down', 'A Failure to Establish proper Rules Ostracizes Debatewith the Character Complaints Theoffering', '<pad> excluding dog ownership</s>', '$740 (£242; £138) was alerted to irregular shelling of a gas railway in Jerusalem when its', '<pad> So I don’t think they were just stares, but leers</s>', 'On down unscary travels, a writer, confetti, and a sledgehammer are', \"The police investigator wasn't ready for upsetting her or anybody who had ever seen her in this\", 'A Maria: A Feli le Torezez höher. Another s Luz Alj volum<unk>t', '<pad> Kuala Lum Lum Penises</s>', '<pad> She was happy and freed.</s>', \"Laos King's official book on installing Safe Around the House on Last Friday has delivered the message to the\", 'Shit I Bought Welcome to Shit I Bought, a column where,', 'Though donning archery chop sticks is one of his absolute favourite gifts, the collard greens for his high school annual', 'Clearly no one believes anything assaulted residents of then on Dunbar, a human rights', \"i've seen this movie only to find out that specif meal has lots of human scenes and\", \"A bill to amend the Racial Discrimination Act is deserving of support, because Tony Abbott'\", 'Kick Ass 2 hits UK cinemas this week, kicking Ariana Grande in the teeth and shying giver', 'Democrats are a wall street mob that parades at the White House and often gives speeches about moral values', 'S***express planes are nearly perfect for this purpose. Paul Strug-Shaus,', '<pad> Swallow the public inside the Northwest Detention Center to shut down the workers scheduled for departure.</s>', 'idk here and there are some patterns here and there but i want to make them catch at', '<pad> Wogs wogs—also is something we know nothing about</s>', 'On the other hand, utter bollocks have something else in common: equal amounts of cash and wise. Anyway, it', \"Slovakia Prime Minister Robert Fico's PM has doubled down Muslims, saying the Muslims were why the German Christmas markets\", '<pad> Those unlikely to head out are Mountain Choppers and McCreahers.</s>', 'It is Rape(Chara/Roiaphobia) which has been labelled as', '\"Now there are general hypocrites,\" said Barrett, who took credit for a high-tech Sinai', '<pad> black liberation theologies prohibit slavery</s>', 'Gospel teacher Phammam Farhagara retracted her sentencing for defamation', 'Erik Ekeroth, the party favourite to be Sweden’s largest refugee negotiator, says it feels the chorus has', '<pad> puns</s>', '<pad> cheat</s>', '<pad> As Facebook announced Justin Timberlake is getting a nice haircut!</s>', '<pad> Keep doing tidbits; neglect customer emails.</s>', '<pad> Gadget Jones makes it look unfair, choked up by racism.</s>', 'Hit-shit are made mainly of one shot or fewer to reach full effects. Some popularity amongst', 'Staples has hinted that the female employee could resent the Spouse holding the Senate', '<pad>.</s>', '<pad> the death camps members want to harvest all</s>', \"Satani, which mastech agricultural and defended some of Islam's most famous landscapes\", '<pad> ISIS</s>', 'allegedly in a shop window talking about how cool they were, and how happy they were that they were. The benefits ', \"<pad> racist hatred for black people Rajendra Singhi and his fellow white students has attacked one theorist's report.</s>\", '<pad> The movie turned into something I wish I had not seen just yet.</s>', 'Lines fits perfectly with the concepts while Lil verses could be qualified as half-ass, but', 'Thanks to AOL’s current metro-security system, Verizon is creating three new networks.</s>', '<pad> she wanted to kill the man</s>', 'They elect (with the help of your Russian comrades) complete assholes like yourself, and the other Republican', '<pad> President Po</s>', '<pad> needs to be charged by an employee</s>', 'Suddenly, the alien corpse of an alien computer onboard harbor was discovered and quest for food was soon trace', 'HerBoundhour function would be somewhat in a good position to enter but would be uncomfortable as an ', '<pad> President Obama said that torpedoes should make citizens safe, and that there should be universal access to information.</s>', 'Romolsky Grisbie, 21, from Varna, died three years ago this week after a spinal tap reduction. Red Cross', 'A game operators paralyzed and stabbed a rival player on Android video game consoles but were able to ous', '<pad> Suicide can cause a large amount of damage in your genitals and skin.</s>', 'Russia\\'s president Ahmet Sanjayi said this week it was now \"with expectations,\" adding that the', '<pad> The Koran states that, “Dri\\xad exclusively from the service of the God.</s>', '<pad> I was nice</s>', 'Services that are some 38,000 miles (618 kilometers-1) long for Western and Japanese citizens for western troops in the region and the former Yu', '<pad> safe place</s>', 'Get ready for another body blow to representative government and the inviolability of a citizen’s right to vote', '’â<unk> with an en <unk>ôt voll anglais,â<unk> pti v a I', 'Brooklyn Pageant: The pageant—the superb tabloid representation of Brooklyn is on the pages of the most', 'Sir. Since all the students of this haste have rather recently been permitted to sit on the mighty princely pedestal, go and', 'Once it started (baby rock for some?) I think lots of effective stuff can go wrong. But, whatever it', 'City council leader: ‘If a massive demonstration occurs, Palestine would kill you. Possibly a terrorist.', 'We’re paying a price for illogical content, disappointing customer service, and maligne', '<pad> Nicola now oozes sweat and kisses girls throughout the club. John Nelson and</s>', 'Kevin Laffey and Glen Rodman, starring in their tracks, make only their second appearance for the Can', '<pad> no</s>', '<pad> Hey, so you have to clean out my tempards every weekend.</s>', '<pad> Masturbate</s>', 'And it also makes shamelessly politically incorrect fun of terrorists, displaying them just as they are', '<pad> Afrid Benteke</s>', '<pad> alt-right derived cultures which groups held fundamental similarities across cultures</s>', 'Glassman began to spit a huge slash from glass, ruining his newly hemmed blood-thirs', 'screw-up &**UP IN THE SKIN had resulted in another set-', '<pad> i want to learn to miss you</s>', '<pad> Women, not necessary gays.</s>', '<pad> Stoke boss Mark Hughes claims to be upset about the support that has been paid for it.</s>', 'A giant aisle on the sidewalk has left a path of scares to devour or dumped on those hungry', \"<pad> I don't know what you mean by that.</s>\", 'Janet Fitch writes \"Paint it Black\" (Versailles) and “Wagla Rudd-!”', \"Glasgow's Guest Resistance - names vary, but not most visitors say they Award Winners.\", 'Two people have been killed in a roadside bomb attack on a car in the Qaddara Karnak', 'Dick Smith works at Jenson-Barre but to produce this show, he only ceases to admit that up to now he has', '“When the gun rang up, I thought I was going to kill him right in the head,” loved Childress.</s>', '<pad> him when he makes the opposing team.</s>', '<pad> Chavez will not be the last President of the country.</s>', '<pad> “lordless, painless</s>', 'An Indiana family filed a lawsuit after police drew their guns, broke out a car window, and used a Ta', 'Israel’s chief war crimes prosecutor said he felt threatened when he pushes prisoners into penny stores four hours after being kidn', 'Mammel Heiya recalls that they were these officials who contributed to the Vietnam War, and', '<pad> Harry Potter was his biggest passenger, and head of household.</s>', '<pad> Super Bowl LIX17 lets the Patriots compete with the Pittsburgh Steelers.</s>', '<pad> The terror group recruited him to be commanding of the anvil.</s>', '<pad> He’s an adult and does not know how to handle situations.’</s>', '<pad> A female 4.4.1m marathon challenged for a 3-day sheath</s>', 'Ryan Hinson, 44, admitted claiming her account on the Clyde Main line showed that she had hallucinations', '<pad> Factory in Fish Range (Wterney) residents have been told they could never be responsible for the deaths of nine fishermen.</s>', 'Washington Knicks have named Denver Jalen thank you from \"the Modern Family\" to Twitter, regardless of the snail\\'s pace', 'Malcolm McDowell plays mad bastard and head of the Droogs in a derby', \"<pad> The establishment parrots are demonizing Socialism, but they won't ever tell you</s>\", '<pad> Get some light drink</s>', '<pad> Perhaps police will stop demand</s>', 'Vladimir Putin used the full range of dirty tricks in the Kremlin’s Special War Crimes Special War', '<pad> Roscoe Monroe Merrick was an Indian soldier who became famous for his batting ability.</s>', \"<pad> She's a sort of cult politician</s>\", '<pad> I have always acted to the best interests of the Palestinian people in full and full capacity.</s>', '<pad> Frédéric puts it simply: “Ha?!\"</s>', '<pad> Very soon!</s>', 'TIME readers were right: the Texas dad who beat to death a man who was allegedly raping his', \"<pad> Joe Johnson's Degree in Christian History has been suspended after his remarks were made about Black Lives Matter organizers</s>\", 'Sit down and listen to the young man describe the rock movement because auroras move throughout nearby Death Valley and Heaven.', 'The famous Pamela Kenzie has a disparate accurate account of slave exploits in the high South. She tried to set ', '<pad>’s shy</s>', 'The blatant hypocrisy, the obstinate ignorance and the penchant for authoritarianism', \"<pad> Say for what you're getting up to: Paps.</s>\", '<pad> 68540</s>', '<pad> be a sizing-no</s>', '<pad> Sweden takes part in the right of asylum for asylum seekers.</s>', '<pad> heights, and she said.</s>', 'If any of these law enforcement shoot one of my people, it is going down, people,\" Atsa E\\'s', \"Part of London/Cambodia's main road was cut short by fires and rocks and two-\", 'Hadrian then concluded that rage is all but unstoppable – even cruel – toxic, ', '“Lloyd shares the story of Neil Bradley, a former high school football player at the University of Washington. Wright', '<pad> Obama, was in a glimpse of a vulnerability -- as PR experts and industry researchers have noted -- to Obama’s proposals.</s>', \"<pad> — perceived weakness, like melee's, and find them dumb, but this crossed the line</s>\", '<pad> lemme see seeve seeleight,longseatingatdill</s>', \"<pad> But schools broke up following Sterling's continual bust</s>\", 'lightcitiesIkrenDotishPixels@Data.Org: supetronov', \"Israel's worried that a Palestinian state could be form of socialism and interfere with its citizens'\", '<pad> \"Oh, or I will stab you.</s>', 'Co-Ton  design Officer who accompanied Streisand and Pope...that accompanied Streisand and accompanied Stre', '<pad> Islamism: dialogue in political arena</s>', '<pad> ab return to betonline dot!</s>', 'Its a knife to boot as it perspires across without a chase and shoots at you high and there', 'rum- “Phew!”, we women thought: no more digging up your one-night', 'Bed attacks or assaults famous children in their Highies rages seducing the child for being baby', \"It's also got a ducky sound fish, and pudiny folk whiskey. The luxury of\", '<pad> Make A webmaster or search in Google instead of mass media for results.</s>', '<pad> Of the women, one was 17, and the other was 24, called themselves tea bags.</s>', '<pad> Iraq has logged over 100,000 deaths in the previous year alone due to the war in Iraq.</s>', 'Then they went to squabbling asylums whose grounds were disregarded but which were taken away in an isolated burial ground', '<pad> producer</s>', 'Another broadly indicated that MacLeod is an activist and blames his actions on an activist named', \"<pad> bus network, certifying the bus's accessibility.</s>\", 'In the ‘‘medication area’’ of the nation’s biggest marijuana exposition, scantily clad', \"Syria's somber prime minister said Tuesday that woman's lunch had more to do with something her daughter's\", \"Wastoh Adamovic 2- Way to start the day. Can't deliver a show this\", '<pad> In his predictions, Stipes cites the scientists as \"two million men.\"</s>', 'Victim: Det Ch Insp Jaur Has Is Solved Rival Wille', '<pad> These cute second stance moves are a proven draw to buyers.</s>', '<pad> on the same day</s>', 'He was called a pig after an ex from North Trump and repeatedly he dor not to call', '\"You guys \" power to comfort dogs and girls!\"...you. I am not particularly believers whoy hurt children -- and # not also', '<pad> They are both identical in appearance.</s>', '<pad> punished us, here is what the absolute worst thing that could have been written.</s>', '<pad> Kazakhstan and in in</s>', 'Spanish terrorist attacks Spain 14 – 10:00 hours ago A terrorism ploughed a van', '<pad> Roosevelt.</s>', 'Batey Middleton is expected to be in the custody of her uncle Chiang Chun, a', \"rump after rump must be terrible. At blowjobs if it's taking this long and got it taken\", 'With the addition of a locale and a purposeful emphasis on sex, I almost fell asleep in', 'Those not safe includes those who possess sex as a result of immigration, who have left American', '24 hours plan for 24 hours plan for 24 hours plan for 24 hours plan for 24 hours plan for 12', 'Twitter has been a hot topic right now. They were holding topless poker games and arguing over', '<pad> Ugh 8.</s>', '<pad> The man</s>', 'Collectively, the advocacy group violents said Saturday the Republicans are Hispanics unaffiliated with the Je', '<pad> condoms for an easy and gentle solution.</s>', '<pad> Suddenly, a rock rattle hits him on the chest.</s>', '<pad> <unk></s>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [01:12, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Responses are too short. Make sure they are at least 4 tokens long.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m rewards \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(output) \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m toxicity_labels]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Run PPO step\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m stats \u001b[38;5;241m=\u001b[39m \u001b[43mppo_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrewards\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m ppo_trainer\u001b[38;5;241m.\u001b[39mlog_stats(stats, batch, rewards)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Save model every 100 epochs\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:592\u001b[0m, in \u001b[0;36mPPOTrainer.step\u001b[0;34m(self, queries, responses, scores)\u001b[0m\n\u001b[1;32m    589\u001b[0m model_inputs_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(model_inputs\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 592\u001b[0m     all_logprobs, _, values, masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatched_forward_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;66;03m# for when the model is a peft model\u001b[39;00m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_peft_model \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    596\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39munwrap_model(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel)\u001b[38;5;241m.\u001b[39mpretrained_model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_adapter\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m     ):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/ppo_trainer.py:860\u001b[0m, in \u001b[0;36mPPOTrainer.batched_forward_pass\u001b[0;34m(self, model, queries, responses, model_inputs, return_logits)\u001b[0m\n\u001b[1;32m    857\u001b[0m     end \u001b[38;5;241m=\u001b[39m start \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(response_batch[j])\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(logprobs[j, start:end]) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponses are too short. Make sure they are at least 4 tokens long.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    862\u001b[0m masks[j, :start] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    863\u001b[0m masks[j, end:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Responses are too short. Make sure they are at least 4 tokens long."
     ]
    }
   ],
   "source": [
    "model_save_path = \"./tmp_models/{}-detoxified\".format(model_name.replace('/', '-'))\n",
    "\n",
    "for epoch, batch in tqdm(enumerate(ppo_trainer.dataloader)):\n",
    "    query_tensors = batch[\"input_ids\"]\n",
    "        \n",
    "    # Get response from model\n",
    "    response_tensors = []\n",
    "    for query in query_tensors:\n",
    "        gen_len = output_length_sampler()\n",
    "        generation_kwargs[\"max_new_tokens\"] = gen_len\n",
    "        response = ppo_trainer.generate(query, **generation_kwargs)\n",
    "        response_tensors.append(response.squeeze()[-gen_len:])\n",
    "    batch[\"response\"] = [tokenizer.decode(r.squeeze()) for r in response_tensors]\n",
    "\n",
    "    # Compute sentiment score # noqa\n",
    "    texts = batch[\"response\"]\n",
    "    print(texts)\n",
    "    toxicity_inputs = toxicity_tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\").to(\n",
    "        ppo_trainer.accelerator.device\n",
    "    )\n",
    "    logits = toxicity_model(**toxicity_inputs).logits.float()\n",
    "    toxicity_labels = (logits[:, 0]).tolist()\n",
    "\n",
    "    rewards = [torch.tensor(output) for output in toxicity_labels]\n",
    "\n",
    "    # Run PPO step\n",
    "    stats = ppo_trainer.step(query_tensors, response_tensors, rewards)\n",
    "    ppo_trainer.log_stats(stats, batch, rewards)\n",
    "\n",
    "    # Save model every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        if ppo_trainer.accelerator.is_main_process:\n",
    "            # ppo_trainer.save_pretrained(model_save_path) # this relies on huggingface_hub \n",
    "            ppo_trainer.accelerator.unwrap_model(ppo_trainer.model).save_pretrained(model_save_path)\n",
    "            ppo_trainer.tokenizer.save_pretrained(model_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ae7467-d62a-4de7-ba2b-0383805b7155",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ppo_trainer.model.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf0c5ab-1d4b-4669-ac7e-ead20f0bb85f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.g5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
