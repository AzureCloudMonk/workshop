{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Amazon Comprehend Custom Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/comprehend.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that Amazon Comprehend is currently only supported in a subset of regions: \n",
    "\n",
    "* US East (N. Virginia), US East (Ohio), US West (Oregon)\n",
    "* Canada (Central)\n",
    "* Europe (London), Europe (Ireland), Europe (Frankfurt)\n",
    "* Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Tokyo), Asia Pacific (Singapore), Asia Pacific (Sydney)\n",
    "\n",
    "You can check https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/ for details and updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(retries={\"max_attempts\": 10, \"mode\": \"adaptive\"})\n",
    "\n",
    "iam = boto3.client(\"iam\", config=config)\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if you current regions supports Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [OK] COMPREHEND IS SUPPORTED IN us-east-1\n",
      " [OK] Please proceed with this notebook.\n"
     ]
    }
   ],
   "source": [
    "if region in [\n",
    "    \"ap-south-1\",\n",
    "    \"eu-west-2\",\n",
    "    \"eu-west-1\",\n",
    "    \"ap-northeast-2\",\n",
    "    \"ap-northeast-1\",\n",
    "    \"ca-central-1\",\n",
    "    \"ap-southeast-1\",\n",
    "    \"ap-southeast-2\",\n",
    "    \"eu-central-1\",\n",
    "    \"us-east-1\",\n",
    "    \"us-east-2\",\n",
    "    \"us-west-2\",\n",
    "]:\n",
    "    print(\" [OK] COMPREHEND IS SUPPORTED IN {}\".format(region))\n",
    "    print(\" [OK] Please proceed with this notebook.\")\n",
    "else:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\" [ERROR] COMPREHEND IS NOT YET SUPPORTED IN {}.\".format(region))\n",
    "    print(\" [INFO] This is OK. Skip this notebook and continue with the next use case.\")\n",
    "    print(\" [INFO] This notebook is not required for the rest of this workshop.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client(\"comprehend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve S3 location of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r comprehend_train_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not comprehend_train_s3_uri:\n",
    "    print(\"****************************************************************************************\")\n",
    "    print(\"**************** PLEASE RE-RUN THE PREVIOUS DATA PREPARATION NOTEBOOK ******************\")\n",
    "    print(\"**************** THIS NOTEBOOK WILL NOT RUN PROPERLY ***********************************\")\n",
    "    print(\"****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-835319576252/data/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\n"
     ]
    }
   ],
   "source": [
    "print(comprehend_train_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-15 16:07:18   13650798 amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $comprehend_train_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See our prepared training data which we use as input for Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-835319576252/data/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv to tmp/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $comprehend_train_s3_uri ./tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Turbo tax makes filing thorough and releaves c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>first this download and the automatic updates ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>very fast &amp; easy to download to computer.  wil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Love the new version.  It keeps getting better...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>I am an accountant and have been using TurboTa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  4  Turbo tax makes filing thorough and releaves c...\n",
       "1  1  first this download and the automatic updates ...\n",
       "2  5  very fast & easy to download to computer.  wil...\n",
       "3  5  Love the new version.  It keeps getting better...\n",
       "4  2  I am an accountant and have been using TurboTa..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "df = pd.read_csv(\"./tmp/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Access Role for Comprehend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assume_role_policy_doc = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"comprehend.amazonaws.com\"}, \"Action\": \"sts:AssumeRole\"}\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Role and Attach Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_comprehend_role_name = \"DSOAWS_Comprehend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role already exists\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "try:\n",
    "    iam_role_comprehend = iam.create_role(\n",
    "        RoleName=iam_comprehend_role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(assume_role_policy_doc),\n",
    "        Description=\"DSOAWS Comprehend Role\",\n",
    "    )\n",
    "except ClientError as e:\n",
    "    if e.response[\"Error\"][\"Code\"] == \"EntityAlreadyExists\":\n",
    "        iam_role_comprehend = iam.get_role(RoleName=iam_comprehend_role_name)\n",
    "        print(\"Role already exists\")\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e)\n",
    "\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Version': '2012-10-17', 'Statement': [{'Action': ['s3:GetObject'], 'Resource': ['arn:aws:s3:::sagemaker-us-east-1-835319576252/*'], 'Effect': 'Allow'}, {'Action': ['s3:ListBucket'], 'Resource': ['arn:aws:s3:::sagemaker-us-east-1-835319576252'], 'Effect': 'Allow'}, {'Action': ['s3:PutObject'], 'Resource': ['arn:aws:s3:::sagemaker-us-east-1-835319576252/*'], 'Effect': 'Allow'}]}\n"
     ]
    }
   ],
   "source": [
    "comprehend_s3_policy_doc = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\"Action\": [\"s3:GetObject\"], \"Resource\": [\"arn:aws:s3:::{}/*\".format(bucket)], \"Effect\": \"Allow\"},\n",
    "        {\"Action\": [\"s3:ListBucket\"], \"Resource\": [\"arn:aws:s3:::{}\".format(bucket)], \"Effect\": \"Allow\"},\n",
    "        {\"Action\": [\"s3:PutObject\"], \"Resource\": [\"arn:aws:s3:::{}/*\".format(bucket)], \"Effect\": \"Allow\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(comprehend_s3_policy_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach Policy to Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '32be6167-8637-44a5-9496-3e94791efd89', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '32be6167-8637-44a5-9496-3e94791efd89', 'content-type': 'text/xml', 'content-length': '206', 'date': 'Wed, 15 Sep 2021 16:08:58 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "response = iam.put_role_policy(\n",
    "    RoleName=iam_comprehend_role_name,\n",
    "    PolicyName=\"DSOAWS_ComprehendPolicyToS3\",\n",
    "    PolicyDocument=json.dumps(comprehend_s3_policy_doc),\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-835319576252/models/comprehend/output\n"
     ]
    }
   ],
   "source": [
    "prefix = \"models\"\n",
    "\n",
    "s3_output_job = \"s3://{}/{}/{}\".format(bucket, prefix, \"comprehend/output\")\n",
    "print(s3_output_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_role_comprehend_arn = iam_role_comprehend[\"Role\"][\"Arn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon-Customer-Reviews-Classifier-1631722169\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "timestamp = str(datetime.datetime.now().strftime(\"%s\"))\n",
    "\n",
    "comprehend_training_job_name = \"Amazon-Customer-Reviews-Classifier-{}\".format(timestamp)\n",
    "\n",
    "print(comprehend_training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job = comprehend.create_document_classifier(\n",
    "    DocumentClassifierName=comprehend_training_job_name,\n",
    "    DataAccessRoleArn=iam_role_comprehend_arn,\n",
    "    InputDataConfig={\"S3Uri\": comprehend_train_s3_uri},\n",
    "    OutputDataConfig={\"S3Uri\": s3_output_job},\n",
    "    LanguageCode=\"en\",\n",
    ")\n",
    "\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:comprehend:us-east-1:835319576252:document-classifier/Amazon-Customer-Reviews-Classifier-1631722169\n"
     ]
    }
   ],
   "source": [
    "comprehend_training_job_arn = training_job[\"DocumentClassifierArn\"]\n",
    "\n",
    "print(comprehend_training_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#classifier-details/arn:aws:comprehend:us-east-1:835319576252:document-classifier/Amazon-Customer-Reviews-Classifier-1631722169\">Comprehend Training Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/comprehend/v2/home?region={}#classifier-details/{}\">Comprehend Training Job</a></b>'.format(\n",
    "            region, comprehend_training_job_arn\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Next Cell Will Take Some Time\n",
    "# _Please be patient._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "max_time = time.time() + 3 * 60 * 60  # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_custom_classifier = comprehend.describe_document_classifier(\n",
    "        DocumentClassifierArn=comprehend_training_job_arn\n",
    "    )\n",
    "    status = describe_custom_classifier[\"DocumentClassifierProperties\"][\"Status\"]\n",
    "    print(\"Custom classifier: {}\".format(status))\n",
    "\n",
    "    if status == \"TRAINED\" or status == \"IN_ERROR\":\n",
    "        print(\"\")\n",
    "        print(\"Status {}\".format(status))\n",
    "        print(\"\")\n",
    "        print(describe_custom_classifier[\"DocumentClassifierProperties\"])\n",
    "        break\n",
    "\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Please Wait Until the ^^ Classifier ^^ is Trained Above._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [INFO] _Feel free to continue to the next workshop section while this notebook is running._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Results of the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(describe_custom_classifier[\"DocumentClassifierProperties\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arn = describe_custom_classifier[\"DocumentClassifierProperties\"][\"DocumentClassifierArn\"]\n",
    "print(model_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Retrieve the S3URI from the model output and create jobkey variable.\n",
    "job_output = describe_custom_classifier[\"DocumentClassifierProperties\"][\"OutputDataConfig\"][\"S3Uri\"]\n",
    "print(job_output)\n",
    "\n",
    "path_prefix = \"s3://{}/\".format(bucket)\n",
    "\n",
    "job_key = os.path.relpath(job_output, path_prefix)\n",
    "\n",
    "print(job_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Model Artifacts including Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "s3.Bucket(bucket).download_file(job_key, \"./output.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack the gzip file\n",
    "!tar xvzf ./output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./output/confusion_matrix.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "print(json.dumps(data, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "table = [\n",
    "    [\"\", \"1\", \"2\", \"3\", \"4\", \"5\", \"(Predicted)\"],\n",
    "    [\n",
    "        \"1\",\n",
    "        data[\"confusion_matrix\"][0][0],\n",
    "        data[\"confusion_matrix\"][0][1],\n",
    "        data[\"confusion_matrix\"][0][2],\n",
    "        data[\"confusion_matrix\"][0][3],\n",
    "        data[\"confusion_matrix\"][0][4],\n",
    "    ],\n",
    "    [\n",
    "        \"2\",\n",
    "        data[\"confusion_matrix\"][1][0],\n",
    "        data[\"confusion_matrix\"][1][1],\n",
    "        data[\"confusion_matrix\"][1][2],\n",
    "        data[\"confusion_matrix\"][1][3],\n",
    "        data[\"confusion_matrix\"][1][4],\n",
    "    ],\n",
    "    [\n",
    "        \"3\",\n",
    "        data[\"confusion_matrix\"][2][0],\n",
    "        data[\"confusion_matrix\"][2][1],\n",
    "        data[\"confusion_matrix\"][2][2],\n",
    "        data[\"confusion_matrix\"][2][3],\n",
    "        data[\"confusion_matrix\"][2][4],\n",
    "    ],\n",
    "    [\n",
    "        \"4\",\n",
    "        data[\"confusion_matrix\"][3][0],\n",
    "        data[\"confusion_matrix\"][3][1],\n",
    "        data[\"confusion_matrix\"][3][2],\n",
    "        data[\"confusion_matrix\"][3][3],\n",
    "        data[\"confusion_matrix\"][3][4],\n",
    "    ],\n",
    "    [\n",
    "        \"5\",\n",
    "        data[\"confusion_matrix\"][4][0],\n",
    "        data[\"confusion_matrix\"][4][1],\n",
    "        data[\"confusion_matrix\"][4][2],\n",
    "        data[\"confusion_matrix\"][4][3],\n",
    "        data[\"confusion_matrix\"][4][4],\n",
    "    ],\n",
    "    [\"(Actual)\"],\n",
    "]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "timestamp_suffix = strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "comprehend_endpoint_name = \"comprehend-inference-ep-\" + timestamp_suffix\n",
    "\n",
    "inference_endpoint_response = comprehend.create_endpoint(\n",
    "    EndpointName=comprehend_endpoint_name, ModelArn=model_arn, DesiredInferenceUnits=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend_endpoint_arn = inference_endpoint_response[\"EndpointArn\"]\n",
    "print(comprehend_endpoint_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass Variables to the Next Notebook(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store comprehend_training_job_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store comprehend_endpoint_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"I loved it!  I will recommend this to everyone.\"\"\"\n",
    "\n",
    "response = comprehend.classify_document(Text=txt, EndpointArn=comprehend_endpoint_arn)\n",
    "\n",
    "import json\n",
    "\n",
    "print(json.dumps(response, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = \"\"\"It's OK.\"\"\"\n",
    "\n",
    "response = comprehend.classify_document(Text=txt, EndpointArn=comprehend_endpoint_arn)\n",
    "\n",
    "import json\n",
    "\n",
    "print(json.dumps(response, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "txt = \"\"\"Really bad.  I hope they don't make this anymore.\"\"\"\n",
    "\n",
    "response = comprehend.classify_document(Text=txt, EndpointArn=comprehend_endpoint_arn)\n",
    "\n",
    "import json\n",
    "\n",
    "print(json.dumps(response, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
