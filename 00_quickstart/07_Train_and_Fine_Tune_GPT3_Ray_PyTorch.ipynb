{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892579b-7f3d-480a-9f03-4d3028368c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "notebook_memory = psutil.virtual_memory()\n",
    "\n",
    "if notebook_memory.total < 32 * 1024 * 1024:\n",
    "    print('*******************************************')    \n",
    "    print('YOU ARE NOT USING THE CORRECT INSTANCE TYPE')\n",
    "    print('PLEASE CHANGE INSTANCE TYPE TO  m5.2xlarge ')\n",
    "    print('*******************************************')\n",
    "else:\n",
    "    correct_instance_type=True\n",
    "    print(notebook_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e58a663f-b3a5-4cc4-8e8c-766a5a878b92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Unable to resolve any data file that matches '['./data-gpt3/gpt3-train/*.parquet']' at /root/data-science-on-aws.quickstart/00_quickstart",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-876ea58815b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlm_dataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data-gpt3/gpt3-train/*.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlm_dataset_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data-gpt3/gpt3-validation/*.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#lm_dataset_test = Dataset.from_parquet('./data-gpt3/gpt3-test/*.parquet')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36mfrom_parquet\u001b[0;34m(path_or_paths, split, features, cache_dir, keep_in_memory, columns, num_proc, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[0mnum_proc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_proc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m         ).read()\n\u001b[1;32m   1120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/io/parquet.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_paths, split, features, cache_dir, keep_in_memory, streaming, num_proc, **kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mhash\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhash\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         )\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/builder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cache_dir, config_name, hash, base_path, info, features, use_auth_token, repo_id, data_files, data_dir, name, **config_kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_files\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFilesDict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             data_files = DataFilesDict.from_local_or_remote(\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0msanitize_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m             )\n\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mfrom_local_or_remote\u001b[0;34m(cls, patterns, base_path, allowed_extensions, use_auth_token)\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                 )\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFilesList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m                 \u001b[0;32melse\u001b[0m \u001b[0mpatterns_for_key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m             )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mfrom_local_or_remote\u001b[0;34m(cls, patterns, base_path, allowed_extensions, use_auth_token)\u001b[0m\n\u001b[1;32m    762\u001b[0m     ) -> \"DataFilesList\":\n\u001b[1;32m    763\u001b[0m         \u001b[0mbase_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbase_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolve_patterns_locally_or_by_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatterns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_extensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0morigin_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_origin_metadata_locally_or_by_urls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigin_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/datasets/data_files.py\u001b[0m in \u001b[0;36mresolve_patterns_locally_or_by_urls\u001b[0;34m(base_path, patterns, allowed_extensions)\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mallowed_extensions\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0merror_msg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\" with any supported extension {list(allowed_extensions)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata_files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: Unable to resolve any data file that matches '['./data-gpt3/gpt3-train/*.parquet']' at /root/data-science-on-aws.quickstart/00_quickstart"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "lm_dataset_train = Dataset.from_parquet('./data-gpt3/gpt3-train/*.parquet')\n",
    "lm_dataset_validation = Dataset.from_parquet('./data-gpt3/gpt3-validation/*.parquet')\n",
    "#lm_dataset_test = Dataset.from_parquet('./data-gpt3/gpt3-test/*.parquet')\n",
    "\n",
    "ray_train_ds = ray.data.from_huggingface(\n",
    "    lm_dataset_train\n",
    ")\n",
    "\n",
    "ray_validation_ds = ray.data.from_huggingface(\n",
    "    lm_dataset_validation\n",
    ")\n",
    "\n",
    "# ray_test_ds = ray.data.from_huggingface(\n",
    "#     lm_dataset_test\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6273fcb-886c-4f57-ab02-b78822e6181c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-15 21:02:20,906\tINFO worker.py:1538 -- Started a local Ray instance.\n",
      "2023-02-15 21:02:22,648\tINFO data_parallel_trainer.py:286 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "/opt/conda/lib/python3.8/site-packages/ray/train/base_trainer.py:354: UserWarning: Executing `.fit()` may leave less than 20% of CPUs in this cluster for Dataset execution, which can lead to resource contention or hangs. To avoid this, reserve at least 20% of node CPUs for Dataset execution by setting `_max_cpu_fraction_per_node = 0.8` in the Trainer scaling_config. See https://docs.ray.io/en/master/data/dataset-internals.html#datasets-and-tune for more info.\n",
      "  tuner = Tuner(trainable=trainable, run_config=self.run_config)\n",
      "2023-02-15 21:02:22,727\tINFO tensorboardx.py:170 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2023-02-15 21:02:22,728\tWARNING callback.py:108 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-02-15 21:48:18</td></tr>\n",
       "<tr><td>Running for: </td><td>00:45:55.53        </td></tr>\n",
       "<tr><td>Memory:      </td><td>16.0/124.6 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Resources requested: 31.0/32 CPUs, 0/1 GPUs, 0.0/95.19 GiB heap, 0.0/14.73 GiB objects (0.0/1.0 accelerator_type:A10G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th>status  </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  loss</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">      epoch</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>HuggingFaceTrainer_0acb7_00000</td><td>RUNNING </td><td>169.255.254.2:14576</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">         1598.64</td><td style=\"text-align: right;\">4.0161</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">0.000860882</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(HuggingFaceTrainer pid=14576)\u001b[0m 2023-02-15 21:02:25,728\tINFO data_parallel_trainer.py:286 -- GPUs are detected in your Ray cluster, but GPU training is not enabled for this trainer. To enable GPU training, make sure to set `use_gpu` to True in your scaling config.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m 2023-02-15 21:02:27,725\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m max_steps is given, it will override any value given in num_train_epochs\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m /opt/conda/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m ***** Running training *****\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m   Num examples = 92921\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m   Num Epochs = 1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m   Instantaneous batch size per device = 8\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m   Gradient Accumulation steps = 1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m   Total optimization steps = 10\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m   Number of trainable parameters = 559214592\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m [W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      " 10%|█         | 1/10 [02:35<23:18, 155.43s/it]\n",
      " 20%|██        | 2/10 [05:09<20:36, 154.51s/it]\n",
      " 30%|███       | 3/10 [07:42<17:58, 154.12s/it]\n",
      " 40%|████      | 4/10 [10:15<15:19, 153.31s/it]\n",
      " 50%|█████     | 5/10 [12:48<12:46, 153.27s/it]\n",
      " 60%|██████    | 6/10 [15:21<10:13, 153.37s/it]\n",
      " 70%|███████   | 7/10 [17:54<07:39, 153.08s/it]\n",
      " 80%|████████  | 8/10 [20:26<05:05, 152.68s/it]\n",
      " 90%|█████████ | 9/10 [22:58<02:32, 152.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m {'loss': 4.0161, 'learning_rate': 0.0, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [25:30<00:00, 152.52s/it]Saving model checkpoint to bigscience/bloom-560m-finetuned-amazon-customer-reviews/checkpoint-10\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m Configuration saved in bigscience/bloom-560m-finetuned-amazon-customer-reviews/checkpoint-10/config.json\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m Configuration saved in bigscience/bloom-560m-finetuned-amazon-customer-reviews/checkpoint-10/generation_config.json\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m Model weights saved in bigscience/bloom-560m-finetuned-amazon-customer-reviews/checkpoint-10/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m {'train_runtime': 1588.9661, 'train_samples_per_second': 0.05, 'train_steps_per_second': 0.006, 'train_loss': 4.016141891479492, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=14712)\u001b[0m \n",
      "100%|██████████| 10/10 [26:28<00:00, 158.90s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th style=\"text-align: right;\">  _time_this_iter_s</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _training_iteration</th><th>date               </th><th>done  </th><th>episodes_total  </th><th style=\"text-align: right;\">      epoch</th><th>experiment_id                   </th><th>hostname                                                       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">  learning_rate</th><th style=\"text-align: right;\">  loss</th><th>node_ip      </th><th style=\"text-align: right;\">  pid</th><th>should_checkpoint  </th><th style=\"text-align: right;\">  step</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  timesteps_since_restore</th><th>timesteps_total  </th><th style=\"text-align: right;\">  train_loss</th><th style=\"text-align: right;\">  train_runtime</th><th style=\"text-align: right;\">  train_samples_per_second</th><th style=\"text-align: right;\">  train_steps_per_second</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  warmup_time</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>HuggingFaceTrainer_0acb7_00000</td><td style=\"text-align: right;\">            1595.64</td><td style=\"text-align: right;\">  1676496544</td><td style=\"text-align: right;\">                    1</td><td>2023-02-15_21-29-04</td><td>False </td><td>                </td><td style=\"text-align: right;\">0.000860882</td><td>c58abde027b646adb64519e3aa670960</td><td>pytorch-1-12-cpu-py3-ml-g5-8xlarge-dadc2efa7892c7009794b397aac6</td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">              0</td><td style=\"text-align: right;\">4.0161</td><td>169.255.254.2</td><td style=\"text-align: right;\">14576</td><td>True               </td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">             1598.64</td><td style=\"text-align: right;\">           1598.64</td><td style=\"text-align: right;\">       1598.64</td><td style=\"text-align: right;\"> 1676496544</td><td style=\"text-align: right;\">                        0</td><td>                 </td><td style=\"text-align: right;\">     4.01614</td><td style=\"text-align: right;\">        1588.97</td><td style=\"text-align: right;\">                      0.05</td><td style=\"text-align: right;\">                   0.006</td><td style=\"text-align: right;\">                   1</td><td>0acb7_00000</td><td style=\"text-align: right;\">   0.00494528</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ray\n",
    "ray.shutdown()\n",
    "\n",
    "from ray.train.huggingface import HuggingFaceTrainer\n",
    "from ray.air.config import ScalingConfig, RunConfig\n",
    "from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForCausalLM\n",
    "from ray.tune import SyncConfig\n",
    "\n",
    "\n",
    "def trainer_init_per_worker(train_dataset, \n",
    "                            eval_dataset, \n",
    "                            **config):\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_checkpoint)\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=f\"{model_checkpoint}-finetuned-amazon-customer-reviews\",\n",
    "#        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,  \n",
    "        max_steps=10,\n",
    "#        eval_steps=10,\n",
    "        num_train_epochs=1.0,\n",
    "        no_cuda=True        \n",
    "    )\n",
    "    \n",
    "    return Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "#        eval_dataset=eval_dataset,\n",
    "    )\n",
    "\n",
    "\n",
    "s3_checkpoint_prefix='./tmp_checkpoint' #\"s3://dsoaws/ray_output\"\n",
    "\n",
    "import multiprocessing\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "scaling_config = ScalingConfig(num_workers=1, \n",
    "                               #use_gpu=True,\n",
    "                               trainer_resources={\"CPU\": num_cpus - 2}, #, \"GPU\": 0},\n",
    "                               #_max_cpu_fraction_per_node = 0.8\n",
    "                              )\n",
    "\n",
    "# If using GPUs, use the below scaling config instead.\n",
    "# scaling_config = ScalingConfig(num_workers=3, use_gpu=True)\n",
    "trainer = HuggingFaceTrainer(\n",
    "    trainer_init_per_worker=trainer_init_per_worker,\n",
    "    scaling_config=scaling_config,\n",
    "    run_config = RunConfig(\n",
    "        sync_config=SyncConfig(\n",
    "            # This will store checkpoints in S3.\n",
    "            upload_dir=s3_checkpoint_prefix\n",
    "        )\n",
    "    ),\n",
    "    datasets={\"train\": ray_train_ds, \n",
    "              #\"evaluation\": ray_evaluation_ds\n",
    "             },\n",
    ")\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb292b81-f621-4601-bf90-0644c5cb299b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result.checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42662f4-3ea2-42d8-958f-b31f4ba81478",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODO.save_pretrained('s3://dsoaws/bloom/output/model_from_notebook_ray/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379679db-65c4-4e12-af87-94e3f6d7a1ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "from transformers import AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bigscience/bloom-560m', use_fast=True)\n",
    "#model = AutoModelForCausalLM.from_pretrained('s3://dsoaws/bloom/output/model_from_notebook_ray/')\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af4a201-2a28-4c2d-ab8b-c4e763d2ffa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "type(trainer.trainer_init_per_worker.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f327a1b-36da-48c0-970f-f84c3b6a0ac7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"Norton Antivirus\"\n",
    "result_length = 100\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "print(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d39171-da7d-4e1b-a278-911909d59508",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(tokenizer.decode(model.generate(inputs[\"input_ids\"],\n",
    "                       max_length=result_length, \n",
    "                       do_sample=True, \n",
    "                       top_k=50, \n",
    "                       top_p=0.9\n",
    "                      )[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05132350-14a0-466e-a191-d1a8ee4f09e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
