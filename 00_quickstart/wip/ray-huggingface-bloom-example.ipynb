{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d32e3d9-761e-4833-8f16-32a2b730285b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (1.13.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.26.1)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.9.0)\n",
      "Requirement already satisfied: ray[air]==2.2.0 in /opt/conda/lib/python3.10/site-packages (2.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (3.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (2.28.1)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (8.0.4)\n",
      "Requirement already satisfied: virtualenv>=20.0.24 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (20.19.0)\n",
      "Requirement already satisfied: aiosignal in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (1.3.1)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (3.20.3)\n",
      "Requirement already satisfied: frozenlist in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (1.3.3)\n",
      "Requirement already satisfied: attrs in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (21.4.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.19.3 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (1.23.5)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (4.17.3)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (1.0.3)\n",
      "Requirement already satisfied: grpcio>=1.42.0 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (1.51.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (21.3)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (0.92.0)\n",
      "Requirement already satisfied: pandas>=1.3 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (1.4.4)\n",
      "Requirement already satisfied: aiorwlock in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (1.3.0)\n",
      "Requirement already satisfied: aiohttp>=3.7 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (3.8.4)\n",
      "Requirement already satisfied: aiohttp-cors in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (0.7.0)\n",
      "Requirement already satisfied: smart-open in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (5.2.1)\n",
      "Requirement already satisfied: gpustat>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: tensorboardX>=1.9 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (2.6)\n",
      "Requirement already satisfied: pydantic in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (1.10.4)\n",
      "Requirement already satisfied: colorful in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (0.5.5)\n",
      "Requirement already satisfied: pyarrow<8.0.0,>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (7.0.0)\n",
      "Requirement already satisfied: starlette in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (0.25.0)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (0.3.14)\n",
      "Requirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (0.8.10)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (2022.7.1)\n",
      "Requirement already satisfied: prometheus-client<0.14.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (0.13.1)\n",
      "Requirement already satisfied: opencensus in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (0.11.1)\n",
      "Requirement already satisfied: uvicorn in /opt/conda/lib/python3.10/site-packages (from ray[air]==2.2.0) (0.20.0)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /opt/conda/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /opt/conda/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.3.0)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /opt/conda/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (63.4.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: dill<0.3.7 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[air]==2.2.0) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[air]==2.2.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[air]==2.2.0) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp>=3.7->ray[air]==2.2.0) (2.0.4)\n",
      "Requirement already satisfied: nvidia-ml-py<=11.495.46,>=11.450.129 in /opt/conda/lib/python3.10/site-packages (from gpustat>=1.0.0->ray[air]==2.2.0) (11.495.46)\n",
      "Requirement already satisfied: psutil>=5.6.0 in /opt/conda/lib/python3.10/site-packages (from gpustat>=1.0.0->ray[air]==2.2.0) (5.9.0)\n",
      "Requirement already satisfied: six>=1.7 in /opt/conda/lib/python3.10/site-packages (from gpustat>=1.0.0->ray[air]==2.2.0) (1.16.0)\n",
      "Requirement already satisfied: blessed>=1.17.1 in /opt/conda/lib/python3.10/site-packages (from gpustat>=1.0.0->ray[air]==2.2.0) (1.20.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray[air]==2.2.0) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3->ray[air]==2.2.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.3->ray[air]==2.2.0) (2022.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray[air]==2.2.0) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray[air]==2.2.0) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray[air]==2.2.0) (2022.9.24)\n",
      "Requirement already satisfied: platformdirs<4,>=2.4 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.0.24->ray[air]==2.2.0) (2.5.2)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in /opt/conda/lib/python3.10/site-packages (from virtualenv>=20.0.24->ray[air]==2.2.0) (0.3.6)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette->ray[air]==2.2.0) (3.5.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray[air]==2.2.0) (0.18.0)\n",
      "Requirement already satisfied: opencensus-context>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[air]==2.2.0) (0.1.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opencensus->ray[air]==2.2.0) (2.11.0)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn->ray[air]==2.2.0) (0.14.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->ray[air]==2.2.0) (1.2.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /opt/conda/lib/python3.10/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[air]==2.2.0) (0.2.5)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]==2.2.0) (1.58.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]==2.2.0) (2.16.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]==2.2.0) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]==2.2.0) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]==2.2.0) (4.7.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[air]==2.2.0) (0.4.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch transformers datasets ray[air]==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aada386f-27f6-4356-831c-f1db7ad9e889",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restart kernel to pick up the pip installs above\n",
    "import IPython\n",
    "\n",
    "IPython.Application.instance().kernel.do_shutdown(True) #automatically restarts kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a058c66-8940-4c77-928e-c89518c88d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76db685e716f42e09ba93ab0d1179754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-5c7ba1a7830bf3c5.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-89a8fcc8c794250d.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-2b9c38818c06a286.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-10df26ed4c5f2e1c.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-1fa889d01415f0c9.arrow\n",
      "Loading cached processed dataset at /root/.cache/huggingface/datasets/wikitext/wikitext-2-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126/cache-8d4df5b5664851f7.arrow\n",
      "2023-02-15 03:46:29,996\tINFO worker.py:1529 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'num_gpus_per_worker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 87\u001b[0m\n\u001b[1;32m     80\u001b[0m scaling_config \u001b[38;5;241m=\u001b[39m ScalingConfig(num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m#                               use_gpu=True,\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m#                               trainer_resources={\"CPU\": 60, \"GPU\": 1}),\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m#                               num_gpus_per_worker=1),\u001b[39;00m\n\u001b[1;32m     84\u001b[0m                                \u001b[38;5;66;03m#_max_cpu_fraction_per_node = 0.8)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;66;03m# If using GPUs, use the below scaling config instead.\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# scaling_config = ScalingConfig(num_workers=3, use_gpu=True)\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer_init_per_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_init_per_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaling_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mray_train_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mray_evaluation_ds\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m result \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ray/train/huggingface/huggingface_trainer.py:356\u001b[0m, in \u001b[0;36mHuggingFaceTrainer.__init__\u001b[0;34m(self, trainer_init_per_worker, datasets, trainer_init_config, torch_config, scaling_config, dataset_config, run_config, preprocessor, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    352\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_trainer_init_per_worker\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a reserved key in `trainer_init_config`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m     )\n\u001b[1;32m    354\u001b[0m trainer_init_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_trainer_init_per_worker\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m trainer_init_per_worker\n\u001b[0;32m--> 356\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loop_per_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_huggingface_train_loop_per_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loop_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainer_init_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaling_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ray/train/torch/torch_trainer.py:198\u001b[0m, in \u001b[0;36mTorchTrainer.__init__\u001b[0;34m(self, train_loop_per_worker, train_loop_config, torch_config, scaling_config, dataset_config, run_config, datasets, preprocessor, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch_config:\n\u001b[1;32m    196\u001b[0m     torch_config \u001b[38;5;241m=\u001b[39m TorchConfig()\n\u001b[0;32m--> 198\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTorchTrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loop_per_worker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loop_per_worker\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loop_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loop_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbackend_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaling_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ray/train/data_parallel_trainer.py:274\u001b[0m, in \u001b[0;36mDataParallelTrainer.__init__\u001b[0;34m(self, train_loop_per_worker, train_loop_config, backend_config, scaling_config, dataset_config, run_config, datasets, preprocessor, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_config \u001b[38;5;241m=\u001b[39m DatasetConfig\u001b[38;5;241m.\u001b[39mvalidated(\n\u001b[1;32m    268\u001b[0m     DatasetConfig\u001b[38;5;241m.\u001b[39mmerge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_config, dataset_config), datasets\n\u001b[1;32m    269\u001b[0m )\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ingest_spec \u001b[38;5;241m=\u001b[39m DataParallelIngestSpec(\n\u001b[1;32m    271\u001b[0m     dataset_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_config,\n\u001b[1;32m    272\u001b[0m )\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDataParallelTrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscaling_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaling_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ray/train/base_trainer.py:162\u001b[0m, in \u001b[0;36mBaseTrainer.__init__\u001b[0;34m(self, scaling_config, run_config, datasets, preprocessor, resume_from_checkpoint)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocessor \u001b[38;5;241m=\u001b[39m preprocessor\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresume_from_checkpoint \u001b[38;5;241m=\u001b[39m resume_from_checkpoint\n\u001b[0;32m--> 162\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/ray/train/huggingface/huggingface_trainer.py:384\u001b[0m, in \u001b[0;36mHuggingFaceTrainer._validate_attributes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m conf\u001b[38;5;241m.\u001b[39muse_stream_api:\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuggingFaceTrainer does not support `use_stream_api`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m         )\n\u001b[0;32m--> 384\u001b[0m gpus_per_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaling_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_gpus_per_worker\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gpus_per_worker \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have assigned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpus_per_worker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GPUs per worker. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is not supported by HuggingFace, which expects \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mone GPU per worker in DDP mode and will fail \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif more are assigned.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    391\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'num_gpus_per_worker'"
     ]
    }
   ],
   "source": [
    "# Based on\n",
    "# huggingface/notebooks/examples/language_modeling_from_scratch.ipynb\n",
    "\n",
    "# Hugging Face imports\n",
    "from datasets import load_dataset\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "import ray\n",
    "ray.shutdown()\n",
    "\n",
    "from ray.train.huggingface import HuggingFaceTrainer\n",
    "from ray.air.config import ScalingConfig\n",
    "\n",
    "model_checkpoint = \"bigscience/bloom\"\n",
    "#tokenizer_checkpoint = \"sgugger/gpt2-like-tokenizer\"\n",
    "block_size = 128\n",
    "\n",
    "datasets = load_dataset(\"wikitext\", \"wikitext-2-raw-v1\")\n",
    "#tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"])\n",
    "\n",
    "\n",
    "tokenized_datasets = datasets.map(\n",
    "    tokenize_function, batched=True, num_proc=1, remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "\n",
    "def group_texts(examples):\n",
    "    # Concatenate all texts.\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    # We drop the small remainder, we could add padding if the model\n",
    "    # supported it.\n",
    "    # instead of this drop, you can customize this part to your needs.\n",
    "    total_length = (total_length // block_size) * block_size\n",
    "    # Split by chunks of max_len.\n",
    "    result = {\n",
    "        k: [t[i : i + block_size] for i in range(0, total_length, block_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "\n",
    "lm_datasets = tokenized_datasets.map(\n",
    "    group_texts,\n",
    "    batched=True,\n",
    "    batch_size=1000,\n",
    "    num_proc=1,\n",
    ")\n",
    "ray_train_ds = ray.data.from_huggingface(lm_datasets[\"train\"])\n",
    "ray_evaluation_ds = ray.data.from_huggingface(lm_datasets[\"validation\"])\n",
    "\n",
    "\n",
    "def trainer_init_per_worker(train_dataset, eval_dataset, **config):\n",
    "    model_config = AutoConfig.from_pretrained(model_checkpoint)\n",
    "    model = AutoModelForCausalLM.from_config(model_config)\n",
    "    args = transformers.TrainingArguments(\n",
    "        output_dir=f\"{model_checkpoint}-wikitext2\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        logging_strategy=\"epoch\",\n",
    "        learning_rate=2e-5,\n",
    "        weight_decay=0.01,\n",
    "        no_cuda=True,  # Set to False for GPU training\n",
    "    )\n",
    "    return transformers.Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=eval_dataset,\n",
    "    )\n",
    "\n",
    "\n",
    "scaling_config = ScalingConfig(num_workers=1), \n",
    "#                               use_gpu=True,\n",
    "#                               trainer_resources={\"CPU\": 60, \"GPU\": 1}),\n",
    "#                               num_gpus_per_worker=1),\n",
    "                               #_max_cpu_fraction_per_node = 0.8)\n",
    "# If using GPUs, use the below scaling config instead.\n",
    "# scaling_config = ScalingConfig(num_workers=3, use_gpu=True)\n",
    "trainer = HuggingFaceTrainer(\n",
    "    trainer_init_per_worker=trainer_init_per_worker,\n",
    "    scaling_config=scaling_config,\n",
    "    datasets={\"train\": ray_train_ds, \"evaluation\": ray_evaluation_ds},\n",
    ")\n",
    "result = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8824fb7-6e7a-42e6-8bf5-cedf92c4e49d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.g5.16xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
