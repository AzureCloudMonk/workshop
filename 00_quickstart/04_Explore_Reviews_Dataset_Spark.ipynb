{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore Amazon Customer Reviews Dataset with Spark and AWS Glue Interactive Sessions\n",
    "For this notebook, we will query a subset of reviews for the Digital Software, Digital Video Games, and Gift Card product categories.  We will also show the results for the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset Column Descriptions\n",
    "\n",
    "- `marketplace`: 2-letter country code (in this case all \"US\").\n",
    "- `customer_id`: Random identifier that can be used to aggregate reviews written by a single author.\n",
    "- `review_id`: A unique ID for the review.\n",
    "- `product_id`: The Amazon Standard Identification Number (ASIN).  `http://www.amazon.com/dp/<ASIN>` links to the product's detail page.\n",
    "- `product_parent`: The parent of that ASIN.  Multiple ASINs (color or format variations of the same product) can roll up into a single parent.\n",
    "- `product_title`: Title description of the product.\n",
    "- `product_category`: Broad product category that can be used to group reviews (in this case digital videos).\n",
    "- `star_rating`: The review's rating (1 to 5 stars).\n",
    "- `helpful_votes`: Number of helpful votes for the review.\n",
    "- `total_votes`: Number of total votes the review received.\n",
    "- `vine`: Was the review written as part of the [Vine](https://www.amazon.com/gp/vine/help) program?\n",
    "- `verified_purchase`: Was the review from a verified purchase?\n",
    "- `review_headline`: The title of the review itself.\n",
    "- `review_body`: The text of the review.\n",
    "- `review_date`: The date the review was written.\n",
    "- `year`: The year derived from the review date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "notebook_memory = psutil.virtual_memory()\n",
    "\n",
    "if notebook_memory.total < 32 * 1024 * 1024:\n",
    "    print('*******************************************')    \n",
    "    print('YOU ARE NOT USING THE CORRECT INSTANCE TYPE')\n",
    "    print('PLEASE CHANGE INSTANCE TYPE TO  m5.2xlarge ')\n",
    "    print('*******************************************')\n",
    "else:\n",
    "    correct_instance_type=True\n",
    "    print(notebook_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r ingest_create_athena_table_parquet_passed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ingest_create_athena_table_parquet_passed\n",
    "except NameError:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN ALL PREVIOUS NOTEBOOKS\")\n",
    "    print(\"You did not convert into Parquet data.        \")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ingest_create_athena_table_parquet_passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ingest_create_athena_table_parquet_passed:\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] YOU HAVE TO RUN ALL PREVIOUS NOTEBOOKS\")\n",
    "    print(\"You did not convert into Parquet data.        \")\n",
    "    print(\"++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "else:\n",
    "    print(\"[OK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping session: 2ca8c9cf-0379-4942-83f1-04b93f69363c\n",
      "Stopped session.\n"
     ]
    }
   ],
   "source": [
    "%stop_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional python modules to be included:\n",
      "seaborn\n",
      "Previous number of workers: 5\n",
      "Setting new number of workers to: 5\n"
     ]
    }
   ],
   "source": [
    "%additional_python_modules seaborn\n",
    "%number_of_workers 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticating with environment variables and user-defined glue_role_arn: arn:aws:iam::079002598131:role/service-role/AmazonSageMaker-ExecutionRole-20220804T150518\n",
      "Trying to create a Glue session for the kernel.\n",
      "Worker Type: G.1X\n",
      "Number of Workers: 5\n",
      "Session ID: 9aa91879-7874-41b9-a177-aaee939f4759\n",
      "Job Type: glueetl\n",
      "Applying the following default arguments:\n",
      "--glue_kernel_version 0.37.2\n",
      "--enable-glue-datacatalog true\n",
      "--additional-python-modules seaborn\n",
      "Waiting for session 9aa91879-7874-41b9-a177-aaee939f4759 to get into ready status...\n",
      "Session 9aa91879-7874-41b9-a177-aaee939f4759 has been created.\n",
      "<pyspark.sql.session.SparkSession object at 0x7f1d04fb4e10>\n"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "database_name = \"default\"\n",
    "table_name = \"amazon_reviews_parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+--------------+----------+--------------+--------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+----+----------------+\n",
      "|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|year|product_category|\n",
      "+-----------+-----------+--------------+----------+--------------+--------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+----+----------------+\n",
      "|         US|   52227601|R3I00Z3RS1192X|B000YMR5X4|     234295632|TurboTax Premier ...|          5|            4|          5|   N|                N|Great download ex...|I have used used ...|      13923|2008|Digital_Software|\n",
      "|         US|   50526871|R1JKRJ049ZHGV9|B008S0IMCC|     534964191| Quicken Deluxe 2013|          4|            0|          0|   N|                Y|Make sure your ba...|I've been using Q...|      15898|2013|Digital_Software|\n",
      "|         US|   52604041|R3C9V2TITW26CR|B000YMR5X4|     234295632|TurboTax Premier ...|          5|            2|          2|   N|                N|Excellent, (speed...|It took 10 minute...|      13968|2008|Digital_Software|\n",
      "|         US|   16645429| RHJIVJBE11FMG|B00A42LWHO|     981240357|H&R Block At Home...|          5|            0|          0|   N|                Y|               Great|Convenient downlo...|      15898|2013|Digital_Software|\n",
      "|         US|   34963673|R2GWPR0XNFA9CG|B001M4JFOA|     546690459|TurboTax Deluxe F...|          2|            9|         10|   N|                N|Do NOT trust this...|Even though I ind...|      14269|2009|Digital_Software|\n",
      "|         US|    7165943|R1CHYT35IPQROX|B008S0IWNQ|     710343641| QuickBooks Pro 2013|          4|            0|          0|   N|                Y|           QB Review|I upgraded from 2...|      15898|2013|Digital_Software|\n",
      "|         US|   48213842|R3VYJHMBKLHKGH|B001O5CHVU|     777469149|H&R Block TaxCut ...|          5|            2|          3|   N|                N|Best Price Availa...|I've been using T...|      14270|2009|Digital_Software|\n",
      "|         US|   40422072|R3T5S9M3X5MLYW|B008SCMUUA|     832031006|Norton Internet S...|          4|            0|          0|   N|                Y|Works well but I ...|Norton keeps my c...|      15898|2013|Digital_Software|\n",
      "|         US|   19125438|R3KDBAFRSGGXN3|B001M4JFOA|     546690459|TurboTax Deluxe F...|          5|            2|          2|   N|                N|Ah its a no brain...|Have been using T...|      14272|2009|Digital_Software|\n",
      "|         US|   32222752| RURO7J662VD5T|B00AFI3GDA|     306617473|Movavi Video Suit...|          5|            0|          0|   N|                N|I love MOVAVI Vid...|At work I had to ...|      15899|2013|Digital_Software|\n",
      "|         US|   18362787|R3CWZ0QYNPSPPC|B001M4JFOA|     546690459|TurboTax Deluxe F...|          4|            3|          3|   N|                N|   Same Old TurboTax|I don't know what...|      14274|2009|Digital_Software|\n",
      "|         US|   22594830| RX3W7794XQBHD|B00B1TFSSS|     189849256|Microsoft Outlook...|          3|            1|          1|   N|                Y|Microsoft Outlook...|I had to buy this...|      15899|2013|Digital_Software|\n",
      "|         US|   30649699| RQYD5MIR85N0Q|B001M4JFT0|     424596157|TurboTax Home & B...|          1|            4|          5|   N|                N|Charge More-Give ...|Like others here ...|      14284|2009|Digital_Software|\n",
      "|         US|   45337009|R3DA4IS7PWY7DN|B009NVU5OS|     283658226|Webroot SecureAny...|          3|            1|          1|   N|                Y|A bit of a slow d...|I had purchased p...|      15899|2013|Digital_Software|\n",
      "|         US|   40202250|R1JIL914U5EWBB|B001O5CHVU|     777469149|H&R Block TaxCut ...|          1|            8|         10|   N|                N|Mac users beware!...|Yes, the governme...|      14290|2009|Digital_Software|\n",
      "|         US|   44050859|R2I0ZIOHD3QKCT|B003PDMNCC|     978035146|Quicken Essential...|          2|            5|          6|   N|                Y|Amended:  Not for...|January 2014:  I ...|      15899|2013|Digital_Software|\n",
      "|         US|   42225765| RV3MO0XYTQ991|B001M4JFOA|     546690459|TurboTax Deluxe F...|          5|            0|          0|   N|                N|Great product, sm...|I had no problem ...|      14292|2009|Digital_Software|\n",
      "|         US|   52087319| RLJ9ABTBJWKF6|B005WX2YH2|     213231757|        Rostta Stone|          3|           76|         79|   N|                Y|NOTE! This versio...|I purchased the \\...|      15900|2013|Digital_Software|\n",
      "|         US|   15485465|R1JWCIGCRD6Y47|B001M4JFOA|     546690459|TurboTax Deluxe F...|          1|            4|          8|   N|                N|Don't understand????|????Don't Underst...|      14298|2009|Digital_Software|\n",
      "|         US|   36837349|R2A04B631CTNLQ|B008S0IMCC|     534964191| Quicken Deluxe 2013|          3|            0|          0|   N|                Y|Dont Waste Your M...|Don't waste your ...|      15900|2013|Digital_Software|\n",
      "+-----------+-----------+--------------+----------+--------------+--------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+----+----------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "product_category = \"Digital_Software\"\n",
    "\n",
    "df = spark.sql(\"\"\"\n",
    "    SELECT * FROM {}.{}\n",
    "    WHERE product_category = '{}' LIMIT 100\n",
    "\"\"\".format(database_name, table_name, product_category)\n",
    ")\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|         review_body|\n",
      "+--------------------+\n",
      "|This program stat...|\n",
      "|This is a complic...|\n",
      "|This the worst pr...|\n",
      "|I bought Music Ma...|\n",
      "|I had to get them...|\n",
      "|I had concerns ab...|\n",
      "|I use this produc...|\n",
      "|[[ASIN:B002K7C1HG...|\n",
      "|I give it a one b...|\n",
      "|I have been using...|\n",
      "|Norton Internet S...|\n",
      "|I just purchased ...|\n",
      "|Hi. I am getting ...|\n",
      "|This key card doe...|\n",
      "|I had a program t...|\n",
      "|I have been impre...|\n",
      "|I have tried this...|\n",
      "|Very used to this...|\n",
      "|I have been using...|\n",
      "|Bought this for a...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "product_category = \"Digital_Software\"\n",
    "\n",
    "df = spark.sql(\"\"\"\n",
    "    SELECT review_body FROM {}.{}\n",
    "    WHERE product_category = '{}' LIMIT 100\n",
    "\"\"\".format(database_name, table_name, product_category)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Seaborn Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnknownMagic: unknown magic command 'matplotlib'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "sns.set_style = \"seaborn-whitegrid\"\n",
    "\n",
    "sns.set(\n",
    "    rc={\n",
    "        \"font.style\": \"normal\",\n",
    "        \"axes.facecolor\": \"white\",\n",
    "        \"grid.color\": \".8\",\n",
    "        \"grid.linestyle\": \"-\",\n",
    "        \"figure.facecolor\": \"white\",\n",
    "        \"figure.titlesize\": 20,\n",
    "        \"text.color\": \"black\",\n",
    "        \"xtick.color\": \"black\",\n",
    "        \"ytick.color\": \"black\",\n",
    "        \"axes.labelcolor\": \"black\",\n",
    "        \"axes.grid\": True,\n",
    "        \"axes.labelsize\": 10,\n",
    "        \"xtick.labelsize\": 10,\n",
    "        \"font.size\": 10,\n",
    "        \"ytick.labelsize\": 10,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Code to Display Values on Bars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_values_barplot(axs, space):\n",
    "#     def _show_on_plot(ax):\n",
    "#         for p in ax.patches:\n",
    "#             _x = p.get_x() + p.get_width() + float(space)\n",
    "#             _y = p.get_y() + p.get_height()\n",
    "#             value = round(float(p.get_width()), 2)\n",
    "#             ax.text(_x, _y, value, ha=\"left\")\n",
    "\n",
    "#     if isinstance(axs, np.ndarray):\n",
    "#         for idx, ax in np.ndenumerate(axs):\n",
    "#             _show_on_plot(ax)\n",
    "#     else:\n",
    "#         _show_on_plot(axs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. Which Product Categories are Highest Rated by Average Rating?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# # SQL statement\n",
    "# statement = \"\"\"\n",
    "#     SELECT product_category, AVG(star_rating) AS avg_star_rating\n",
    "#     FROM {}.{} \n",
    "#     WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')\n",
    "#     GROUP BY product_category \n",
    "#     ORDER BY avg_star_rating DESC\n",
    "# \"\"\".format(\n",
    "#     database_name, table_name\n",
    "# )\n",
    "\n",
    "# print(statement)\n",
    "\n",
    "# df = pd.read_sql(statement, conn)\n",
    "# df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+------------------+\n",
      "|   product_category|   avg_star_rating|\n",
      "+-------------------+------------------+\n",
      "|          Gift_Card| 4.731363105858364|\n",
      "|Digital_Video_Games|3.8531262248076406|\n",
      "|   Digital_Software|3.5393303553935973|\n",
      "+-------------------+------------------+\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"\"\"SELECT product_category, AVG(star_rating) AS avg_star_rating \n",
    "    FROM {}.{} \n",
    "    WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')\n",
    "    GROUP BY product_category \n",
    "    ORDER BY avg_star_rating DESC\"\"\".format(database_name, table_name)\n",
    ")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# df = spark.read.parquet('s3://amazon-reviews-pds/parquet/')\n",
    "\n",
    "\n",
    "# from pyspark.sql.functions import avg, desc\n",
    "\n",
    "# df_avg_rating_per_product_category = df.groupBy('product_category') \\\n",
    "#                                        .agg(avg('star_rating').alias('avg_star_rating')) \\\n",
    "#                                        .sort(desc('avg_star_rating'))\n",
    "# df_avg_rating_per_product_category.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Store number of categories\n",
    "# num_categories = df.shape[0]\n",
    "# print(num_categories)\n",
    "\n",
    "# # Store average star ratings\n",
    "# average_star_ratings = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for a Subset of Product Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create plot\n",
    "# barplot = sns.barplot(y=\"product_category\", x=\"avg_star_rating\", data=df, saturation=1)\n",
    "\n",
    "# if num_categories < 10:\n",
    "#     sns.set(rc={\"figure.figsize\": (10.0, 5.0)})\n",
    "\n",
    "# # Set title and x-axis ticks\n",
    "# plt.title(\"Average Rating by Product Category\")\n",
    "# plt.xticks([1, 2, 3, 4, 5], [\"1-Star\", \"2-Star\", \"3-Star\", \"4-Star\", \"5-Star\"])\n",
    "\n",
    "# # Helper code to show actual values afters bars\n",
    "# show_values_barplot(barplot, 0.1)\n",
    "\n",
    "# plt.xlabel(\"Average Rating\")\n",
    "# plt.ylabel(\"Product Category\")\n",
    "\n",
    "# # Export plot if needed\n",
    "# plt.tight_layout()\n",
    "# # plt.savefig('avg_ratings_per_category.png', dpi=300)\n",
    "\n",
    "# # Show graphic\n",
    "# plt.show(barplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following visualization:\n",
    "\n",
    "<img src=\"img/c5-01.png\"  width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Which Product Categories Have the Most Reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|   product_category|count_star_rating|\n",
      "+-------------------+-----------------+\n",
      "|          Gift_Card|           149086|\n",
      "|Digital_Video_Games|           145431|\n",
      "|   Digital_Software|           102084|\n",
      "+-------------------+-----------------+\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "    SELECT product_category, COUNT(star_rating) AS count_star_rating \n",
    "    FROM {}.{}\n",
    "    WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')    \n",
    "    GROUP BY product_category \n",
    "    ORDER BY count_star_rating DESC\n",
    "\"\"\".format(database_name, table_name)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError: 'Column' object is not callable\n"
     ]
    }
   ],
   "source": [
    "# # Store counts\n",
    "# count_ratings = df[\"count_star_rating\"]\n",
    "\n",
    "# # Store max ratings\n",
    "# max_ratings = df[\"count_star_rating\"].max()\n",
    "# print(max_ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for a Subset of Product Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create Seaborn barplot\n",
    "# barplot = sns.barplot(y=\"product_category\", x=\"count_star_rating\", data=df, saturation=1)\n",
    "\n",
    "# if num_categories < 10:\n",
    "#     sns.set(rc={\"figure.figsize\": (10.0, 5.0)})\n",
    "\n",
    "# # Set title\n",
    "# plt.title(\"Number of Ratings per Product Category for Subset of Product Categories\")\n",
    "\n",
    "# # Set x-axis ticks to match scale\n",
    "# if max_ratings > 200000:\n",
    "#     plt.xticks([100000, 1000000, 5000000, 10000000, 15000000, 20000000], [\"100K\", \"1m\", \"5m\", \"10m\", \"15m\", \"20m\"])\n",
    "#     plt.xlim(0, 20000000)\n",
    "# elif max_ratings <= 200000:\n",
    "#     plt.xticks([50000, 100000, 150000, 200000], [\"50K\", \"100K\", \"150K\", \"200K\"])\n",
    "#     plt.xlim(0, 200000)\n",
    "\n",
    "# plt.xlabel(\"Number of Ratings\")\n",
    "# plt.ylabel(\"Product Category\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Export plot if needed\n",
    "# # plt.savefig('ratings_per_category.png', dpi=300)\n",
    "\n",
    "# # Show the barplot\n",
    "# plt.show(barplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following visualization:\n",
    "\n",
    "<img src=\"img/c5-02.png\"  width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. When did each product category become available in the Amazon catalog based on the date of the first review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL statement\n",
    "df = spark.sql(\"\"\"\n",
    "    SELECT product_category, MIN(year) AS first_review_year\n",
    "    FROM {}.{}\n",
    "    WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')    \n",
    "    GROUP BY product_category\n",
    "    ORDER BY first_review_year \n",
    "\"\"\".format(database_name, table_name)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_x_y(df):\n",
    "#     \"\"\" Get X and Y coordinates; return tuple \"\"\"\n",
    "#     series = df[\"first_review_year\"].value_counts().sort_index()\n",
    "#     # new_series = series.reindex(range(1,21)).fillna(0).astype(int)\n",
    "#     return series.index, series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, Y = get_x_y(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for a Subset of Product Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(12, 5))\n",
    "# ax = plt.gca()\n",
    "\n",
    "# ax.set_title(\"Number Of First Product Category Reviews Per Year for Subset of Categories\")\n",
    "# ax.set_xlabel(\"Year\")\n",
    "# ax.set_ylabel(\"Count\")\n",
    "\n",
    "# ax.plot(X, Y, color=\"black\", linewidth=2, marker=\"o\")\n",
    "# ax.fill_between(X, [0] * len(X), Y, facecolor=\"lightblue\")\n",
    "\n",
    "# ax.locator_params(integer=True)\n",
    "\n",
    "# ax.set_xticks(range(1995, 2016, 1))\n",
    "# ax.set_yticks(range(0, max(Y) + 2, 1))\n",
    "\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# # fig.savefig('first_reviews_per_year.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following visualization:\n",
    "\n",
    "<img src=\"img/c4-04.png\"  width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. What is the breakdown of ratings (1-5) per product category?  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------+-------------+\n",
      "|product_category|star_rating|count_reviews|\n",
      "+----------------+-----------+-------------+\n",
      "|         Apparel|          5|      3320651|\n",
      "|         Apparel|          4|      1147254|\n",
      "|         Apparel|          3|       623483|\n",
      "|         Apparel|          2|       369608|\n",
      "|         Apparel|          1|       445464|\n",
      "|      Automotive|          5|      2301688|\n",
      "|      Automotive|          4|       526898|\n",
      "|      Automotive|          3|       240023|\n",
      "|      Automotive|          2|       147843|\n",
      "|      Automotive|          1|       300024|\n",
      "|            Baby|          5|      1078545|\n",
      "|            Baby|          4|       289129|\n",
      "|            Baby|          3|       150753|\n",
      "|            Baby|          2|       101427|\n",
      "|            Baby|          1|       145039|\n",
      "|          Beauty|          5|      3254946|\n",
      "|          Beauty|          4|       741443|\n",
      "|          Beauty|          3|       398405|\n",
      "|          Beauty|          2|       264029|\n",
      "|          Beauty|          1|       456898|\n",
      "+----------------+-----------+-------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# SQL statement\n",
    "df = spark.sql(\"\"\"\n",
    "    SELECT product_category, star_rating, COUNT(*) AS count_reviews\n",
    "    FROM {}.{}\n",
    "    WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')    \n",
    "    GROUP BY  product_category, star_rating\n",
    "    ORDER BY  product_category ASC, star_rating DESC, count_reviews\n",
    "\"\"\".format(database_name, table_name)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare for Stacked Percentage Horizontal Bar Plot Showing Proportion of Star Ratings per Product Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnalysisException: Cannot resolve column name \"count_reviews\" among (star_rating, sum(star_rating), sum(count_reviews))\n"
     ]
    }
   ],
   "source": [
    "# # Create grouped DataFrames by category and by star rating\n",
    "# grouped_category = df.groupby(\"product_category\")\n",
    "# grouped_star = df.groupby(\"star_rating\")\n",
    "\n",
    "# # Create sum of ratings per star rating\n",
    "# df_sum = df.groupby([\"star_rating\"]).sum()\n",
    "\n",
    "# # Calculate total number of star ratings\n",
    "# total = df_sum[\"count_reviews\"].sum()\n",
    "# print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dictionary of product categories and array of star rating distribution per category\n",
    "# distribution = {}\n",
    "# count_reviews_per_star = []\n",
    "# i = 0\n",
    "\n",
    "# for category, ratings in grouped_category:\n",
    "#     count_reviews_per_star = []\n",
    "#     for star in ratings[\"star_rating\"]:\n",
    "#         count_reviews_per_star.append(ratings.at[i, \"count_reviews\"])\n",
    "#         i = i + 1\n",
    "#     distribution[category] = count_reviews_per_star\n",
    "\n",
    "# # Check if distribution has been created succesfully\n",
    "# print(distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if distribution keys are set correctly to product categories\n",
    "# print(distribution.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if star rating distributions are set correctly\n",
    "# print(distribution.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sort distribution by average rating per category\n",
    "# sorted_distribution = {}\n",
    "\n",
    "# average_star_ratings.iloc[:, 0]\n",
    "# for index, value in average_star_ratings.iloc[:, 0].items():\n",
    "#     sorted_distribution[value] = distribution[value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sorted_distribution_pct = pd.DataFrame(sorted_distribution).transpose().apply(\n",
    "#     lambda num_ratings: num_ratings/sum(num_ratings)*100, axis=1\n",
    "# )\n",
    "# df_sorted_distribution_pct.columns=['5', '4', '3', '2', '1']\n",
    "# df_sorted_distribution_pct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for a Subset of Product Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categories = df_sorted_distribution_pct.index\n",
    "\n",
    "# # Plot bars\n",
    "# if len(categories) > 10:\n",
    "#     plt.figure(figsize=(10,10))\n",
    "# else: \n",
    "#     plt.figure(figsize=(10,5))\n",
    "\n",
    "# df_sorted_distribution_pct.plot(kind=\"barh\", \n",
    "#                                 stacked=True, \n",
    "#                                 edgecolor='white',\n",
    "#                                 width=1.0,\n",
    "#                                 color=['green', \n",
    "#                                        'orange', \n",
    "#                                        'blue', \n",
    "#                                        'purple', \n",
    "#                                        'red'])\n",
    "\n",
    "# plt.title(\"Distribution of Reviews Per Rating Per Category\", \n",
    "#           fontsize='16')\n",
    "\n",
    "# plt.legend(bbox_to_anchor=(1.04,1), \n",
    "#            loc=\"upper left\",\n",
    "#            labels=['5-Star Ratings', \n",
    "#                    '4-Star Ratings', \n",
    "#                    '3-Star Ratings', \n",
    "#                    '2-Star Ratings', \n",
    "#                    '1-Star Ratings'])\n",
    "\n",
    "# plt.xlabel(\"% Breakdown of Star Ratings\", fontsize='14')\n",
    "# plt.gca().invert_yaxis()\n",
    "# plt.tight_layout()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following visualization:\n",
    "\n",
    "<img src=\"img/c5-04.png\"  width=\"70%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. How Many Reviews per Star Rating? (5, 4, 3, 2, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|star_rating|count_reviews|\n",
      "+-----------+-------------+\n",
      "|          5|       256796|\n",
      "|          4|        46958|\n",
      "|          3|        23093|\n",
      "|          2|        16208|\n",
      "|          1|        53546|\n",
      "+-----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "# SQL statement\n",
    "df = spark.sql(\"\"\"\n",
    "    SELECT star_rating, COUNT(*) AS count_reviews\n",
    "    FROM {}.{}\n",
    "    WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')\n",
    "    GROUP BY star_rating\n",
    "    ORDER BY star_rating DESC, count_reviews \n",
    "\"\"\".format(database_name, table_name)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following result:\n",
    "\n",
    "<img src=\"img/star_rating_count_all.png\"  width=\"25%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart = df.plot.bar(\n",
    "#     x=\"star_rating\", y=\"count_reviews\", rot=\"0\", figsize=(10, 5), title=\"Review Count by Star Ratings\", legend=False\n",
    "# )\n",
    "\n",
    "# plt.xlabel(\"Star Rating\")\n",
    "# plt.ylabel(\"Review Count\")\n",
    "\n",
    "# plt.show(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following result:\n",
    "\n",
    "\n",
    "<img src=\"img/star_rating_count_all_bar_chart.png\"  width=\"70%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. How Did Star Ratings Change Over Time?\n",
    "Is there a drop-off point for certain product categories throughout the year?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Star Rating Across All Product Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------+\n",
      "|year|avg_rating|\n",
      "+----+----------+\n",
      "|2004|       4.5|\n",
      "|2005|    3.2759|\n",
      "|2006|     3.375|\n",
      "|2007|      3.95|\n",
      "|2008|    2.8966|\n",
      "|2009|    3.7288|\n",
      "|2010|    3.7614|\n",
      "|2011|    3.9808|\n",
      "|2012|    4.0955|\n",
      "|2013|     4.008|\n",
      "|2014|    4.2026|\n",
      "|2015|    4.1125|\n",
      "+----+----------+\n"
     ]
    }
   ],
   "source": [
    "# SQL statement\n",
    "df = spark.sql(\"\"\"\n",
    "    SELECT year, ROUND(AVG(star_rating),4) AS avg_rating\n",
    "    FROM {}.{}\n",
    "    WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')    \n",
    "    GROUP BY year\n",
    "    ORDER BY year\n",
    "\"\"\".format(database_name, table_name)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"year\"] = pd.to_datetime(df[\"year\"], format=\"%Y\").dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for a Subset of Product Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.gcf()\n",
    "# fig.set_size_inches(12, 5)\n",
    "\n",
    "# fig.suptitle(\"Average Star Rating Over Time (Across Subset of Product Categories)\")\n",
    "\n",
    "# ax = plt.gca()\n",
    "# # ax = plt.gca().set_xticks(df['year'])\n",
    "# ax.locator_params(integer=True)\n",
    "# ax.set_xticks(df[\"year\"].unique())\n",
    "\n",
    "# df.plot(kind=\"line\", x=\"year\", y=\"avg_rating\", color=\"red\", ax=ax)\n",
    "\n",
    "# # plt.xticks(range(1995, 2016, 1))\n",
    "# # plt.yticks(range(0,6,1))\n",
    "# plt.xlabel(\"Years\")\n",
    "# plt.ylabel(\"Average Star Rating\")\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# # fig.savefig('average-rating.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following visualization:\n",
    "\n",
    "<img src=\"img/c4-06.png\"  width=\"70%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Star Rating Per Product Categories Across Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----+-------------------+\n",
      "|   product_category|year|avg_rating_category|\n",
      "+-------------------+----+-------------------+\n",
      "|          Gift_Card|2004|                4.5|\n",
      "|          Gift_Card|2005|             3.2759|\n",
      "|          Gift_Card|2006|             3.2857|\n",
      "|Digital_Video_Games|2006|                4.0|\n",
      "|          Gift_Card|2007|               3.95|\n",
      "|Digital_Video_Games|2008|                2.0|\n",
      "|          Gift_Card|2008|             3.3043|\n",
      "|   Digital_Software|2008|             2.7333|\n",
      "|   Digital_Software|2009|             2.7603|\n",
      "|          Gift_Card|2009|             3.9389|\n",
      "|Digital_Video_Games|2009|             3.8924|\n",
      "|Digital_Video_Games|2010|             3.7338|\n",
      "|          Gift_Card|2010|              4.307|\n",
      "|   Digital_Software|2010|             3.1268|\n",
      "|          Gift_Card|2011|             4.5916|\n",
      "|   Digital_Software|2011|             3.4667|\n",
      "|Digital_Video_Games|2011|             3.6484|\n",
      "|          Gift_Card|2012|             4.7119|\n",
      "|   Digital_Software|2012|             3.3902|\n",
      "|Digital_Video_Games|2012|             3.6839|\n",
      "+-------------------+----+-------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "# SQL statement\n",
    "df = spark.sql(\"\"\"\n",
    "    SELECT product_category, year, ROUND(AVG(star_rating), 4) AS avg_rating_category\n",
    "    FROM {}.{}\n",
    "    WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')    \n",
    "    GROUP BY product_category, year\n",
    "    ORDER BY year \n",
    "\"\"\".format(database_name, table_name)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot_categories(df):\n",
    "#     df_categories = df[\"product_category\"].unique()\n",
    "#     for category in df_categories:\n",
    "#         # print(category)\n",
    "#         df_plot = df.loc[df[\"product_category\"] == category]\n",
    "#         df_plot.plot(\n",
    "#             kind=\"line\",\n",
    "#             x=\"year\",\n",
    "#             y=\"avg_rating_category\",\n",
    "#             c=np.random.rand(\n",
    "#                 3,\n",
    "#             ),\n",
    "#             ax=ax,\n",
    "#             label=category,\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.gcf()\n",
    "# fig.set_size_inches(12, 5)\n",
    "\n",
    "# fig.suptitle(\"Average Star Rating Over Time Across Subset Of Categories\")\n",
    "\n",
    "# ax = plt.gca()\n",
    "\n",
    "# ax.locator_params(integer=True)\n",
    "# ax.set_xticks(df[\"year\"].unique())\n",
    "\n",
    "# plot_categories(df)\n",
    "\n",
    "# plt.xlabel(\"Year\")\n",
    "# plt.ylabel(\"Average Star Rating\")\n",
    "# plt.legend(bbox_to_anchor=(0, -0.15, 1, 0), loc=2, ncol=2, mode=\"expand\", borderaxespad=0)\n",
    "\n",
    "# # fig.savefig('average_rating_category_all_data.png', dpi=300)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for All Product Categories\n",
    "If you ran this same query across all product categories, you would see the following visualization:\n",
    "\n",
    "<img src=\"img/average_rating_category_all_data.png\"  width=\"70%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Which Star Ratings (1-5) are Most Helpful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|star_rating| avg_helpful_votes|\n",
      "+-----------+------------------+\n",
      "|          1|4.8907294662533145|\n",
      "|          2| 2.493028134254689|\n",
      "|          3|1.5595635040921492|\n",
      "|          4|1.0709357298010989|\n",
      "|          5|0.5324966120967616|\n",
      "+-----------+------------------+\n"
     ]
    }
   ],
   "source": [
    "# SQL statement\n",
    "df = spark.sql(\"\"\"\n",
    "    SELECT star_rating, AVG(helpful_votes) AS avg_helpful_votes\n",
    "    FROM {}.{}\n",
    "    WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')\n",
    "    GROUP BY  star_rating\n",
    "    ORDER BY  star_rating ASC\n",
    "\"\"\".format(database_name, table_name)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following result:\n",
    "\n",
    "<img src=\"img/star_rating_helpful_all.png\"  width=\"25%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for a Subset of Product Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart = df.plot.bar(\n",
    "#     x=\"star_rating\", y=\"avg_helpful_votes\", rot=\"0\", figsize=(10, 5), title=\"Helpfulness Of Star Ratings\", legend=False\n",
    "# )\n",
    "\n",
    "# plt.xlabel(\"Star Rating\")\n",
    "# plt.ylabel(\"Average Helpful Votes\")\n",
    "\n",
    "# plt.show(chart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following visualization:\n",
    "\n",
    "<img src=\"img/c4-08.png\"  width=\"60%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Which Products have Most Helpful Reviews?  How Long are the Most Helpful Reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+-----------+------------------+--------------------+\n",
      "|       product_title|helpful_votes|star_rating|review_body_length|  review_body_substr|\n",
      "+--------------------+-------------+-----------+------------------+--------------------+\n",
      "|Amazon.com eGift ...|         5987|          1|              3498|I think I am just...|\n",
      "|TurboTax Deluxe F...|         5363|          1|              3696|I have been a loy...|\n",
      "|SimCity - Limited...|         5068|          1|              2478|Guess what? If yo...|\n",
      "|SimCity - Limited...|         3789|          1|              1423|How would you fee...|\n",
      "|Microsoft Office ...|         2955|          1|              4932|I have never been...|\n",
      "|SimCity - Limited...|         2509|          5|              1171|You'd think I'd b...|\n",
      "|TurboTax Deluxe F...|         2439|          1|              3710|Although a long t...|\n",
      "|Playstation Netwo...|         2384|          5|               190|$49.99 for $50 of...|\n",
      "|Amazon eGift Card...|         2383|          4|               463|I've used the gif...|\n",
      "|Amazon eGift Card...|         2231|          2|               410|This is the secon...|\n",
      "+--------------------+-------------+-----------+------------------+--------------------+\n"
     ]
    }
   ],
   "source": [
    "# SQL statement\n",
    "df = spark.sql(\"\"\"\n",
    "    SELECT product_title, helpful_votes, star_rating,\n",
    "           LENGTH(review_body) AS review_body_length,\n",
    "           SUBSTR(review_body, 1, 100) AS review_body_substr\n",
    "    FROM {}.{}\n",
    "    WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')\n",
    "    ORDER BY helpful_votes DESC LIMIT 10 \n",
    "\"\"\".format(database_name, table_name)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following result:\n",
    "\n",
    "<img src=\"img/most_helpful_all.png\"  width=\"90%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. What is the Ratio of Positive (5, 4) to Negative (3, 2 ,1) Reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|positive_to_negative_sentiment_ratio|\n",
      "+------------------------------------+\n",
      "|                   3.271554277467231|\n",
      "+------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# SQL statement\n",
    "df = spark.sql(\"\"\"\n",
    "    SELECT (CAST(positive_review_count AS DOUBLE) / CAST(negative_review_count AS DOUBLE)) AS positive_to_negative_sentiment_ratio\n",
    "    FROM (\n",
    "      SELECT count(*) AS positive_review_count\n",
    "      FROM {}.{}\n",
    "      WHERE star_rating >= 4 and product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')\n",
    "\n",
    "    ), (\n",
    "      SELECT count(*) AS negative_review_count\n",
    "      FROM {}.{}\n",
    "      WHERE star_rating < 4 and product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')\n",
    "    )\n",
    "\"\"\".format(database_name, table_name, database_name, table_name)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following result:\n",
    "\n",
    "<img src=\"img/ratio_all.png\"  width=\"25%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Which Customers are Abusing the Review System by Repeatedly Reviewing the Same Product?  What Was Their Average Star Rating for Each Product?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|positive_to_negative_sentiment_ratio|\n",
      "+------------------------------------+\n",
      "|                   3.271554277467231|\n",
      "+------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# SQL statement\n",
    "spark.sql(\"\"\"\n",
    "    SELECT customer_id, product_category, product_title, \n",
    "    ROUND(AVG(star_rating),4) AS avg_star_rating, COUNT(*) AS review_count \n",
    "    FROM {}.{} \n",
    "    WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')    \n",
    "    GROUP BY customer_id, product_category, product_title \n",
    "    HAVING COUNT(*) > 1 \n",
    "    ORDER BY review_count DESC\n",
    "    LIMIT 5\n",
    "\"\"\".format(database_name, table_name)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for All Product Categories\n",
    "If you ran this same query across all product categories (150+ million reviews), you would see the following result:\n",
    "  \n",
    "<img src=\"img/athena-abuse-all.png\"  width=\"60%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. What is the distribution of review lengths (number of words)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|num_words|\n",
      "+---------+\n",
      "|      107|\n",
      "|        4|\n",
      "|      170|\n",
      "|       18|\n",
      "|       21|\n",
      "|        6|\n",
      "|       64|\n",
      "|       10|\n",
      "|       28|\n",
      "|        5|\n",
      "|      206|\n",
      "|        2|\n",
      "|      146|\n",
      "|        5|\n",
      "|      200|\n",
      "|      132|\n",
      "|       45|\n",
      "|       11|\n",
      "|      146|\n",
      "|      150|\n",
      "+---------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"\"\"\n",
    "    SELECT CARDINALITY(SPLIT(review_body, ' ')) as num_words\n",
    "    FROM {}.{}\n",
    "    WHERE product_category in ('Digital_Software', 'Gift_Card', 'Digital_Video_Games')\n",
    "\"\"\".format(database_name, table_name)\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TypeError: 'Column' object is not callable\n"
     ]
    }
   ],
   "source": [
    "# summary = df[\"num_words\"].describe(percentiles=[0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.00])\n",
    "# summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"num_words\"].plot.hist(xticks=[0, 16, 32, 64, 128, 256], bins=100, range=[0, 256]).axvline(\n",
    "#     x=summary[\"80%\"], c=\"red\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/max_seq_length_viz.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "instance_type": "ml.m5.2xlarge",
  "kernelspec": {
   "display_name": "Glue Python [PySpark and Ray] (SparkAnalytics 1.0)",
   "language": "python",
   "name": "conda-env-sm_glue_is-glue_pyspark__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-sparkanalytics-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "Python_Glue_Session",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
