{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Armed Bandits and Reinforcement Learning with Amazon SageMaker\n",
    "\n",
    "We demonstrate how you can manage your own contextual multi-armed bandit workflow on SageMaker using the built-in [AWS Reinforcement Learning Container](https://github.com/aws/sagemaker-rl-container) container to train and deploy contextual bandit models. We show how to train these models that interact with a live environment (using a simulated client application) and continuously update the model with efficient exploration.\n",
    "\n",
    "### Why Contextual Bandits?\n",
    "\n",
    "Wherever we look to personalize content for a user (content layout, ads, search, product recommendations, etc.), contextual bandits come in handy. Traditional personalization methods collect a training dataset, build a model and deploy it for generating recommendations. However, the training algorithm does not inform us on how to collect this dataset, especially in a production system where generating poor recommendations lead to loss of revenue. Contextual bandit algorithms help us collect this data in a strategic manner by trading off between exploiting known information and exploring recommendations which may yield higher benefits. The collected data is used to update the personalization model in an online manner. Therefore, contextual bandits help us train a personalization model while minimizing the impact of poor recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/multi_armed_bandit_maximize_reward.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement the exploration-exploitation strategy, we need an iterative training and deployment system that: (1) recommends an action using the contextual bandit model based on user context, (2) captures the implicit feedback over time and (3) continuously trains the model with incremental interaction data. In this notebook, we show how to setup the infrastructure needed for such an iterative learning system. While the example demonstrates a bandits application, these continual learning systems are useful more generally in dynamic scenarios where models need to be continually updated to capture the recent trends in the data (e.g. tracking fraud behaviors based on detection mechanisms or tracking user interests over time). \n",
    "\n",
    "In a typical supervised learning setup, the model is trained with a SageMaker training job and it is hosted behind a SageMaker hosting endpoint. The client application calls the endpoint for inference and receives a response. In bandits, the client application also sends the reward (a score assigned to each recommendation generated by the model) back for subsequent model training. These rewards will be part of the dataset for the subsequent model training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relevant Links\n",
    "\n",
    "In-Practice\n",
    "* [AWS Blog Post on Contextual Multi-Armed Bandits](https://aws.amazon.com/blogs/machine-learning/power-contextual-bandits-using-continual-learning-with-amazon-sagemaker-rl/)\n",
    "* [Multi-Armed Bandits at StitchFix](https://multithreaded.stitchfix.com/blog/2020/08/05/bandits/)\n",
    "* [Introduction to Contextual Bandits](https://getstream.io/blog/introduction-contextual-bandits/)\n",
    "* [Vowpal Wabbit Contextual Bandit Algorithms](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Contextual-Bandit-algorithms)\n",
    "\n",
    "Theory\n",
    "* [Learning to Interact](https://hunch.net/~jl/interact.pdf)\n",
    "* [Contextual Bandit Bake-Off](https://arxiv.org/pdf/1802.04064.pdf)\n",
    "* [Doubly-Robust Policy Evaluation and Learning](https://arxiv.org/pdf/1103.4601.pdf)\n",
    "\n",
    "Code\n",
    "* [AWS Open Source Reinforcement Learning Containers](https://github.com/aws/sagemaker-rl-container)\n",
    "* [AWS Open Source Bandit Experiment Manager](./common/sagemaker_rl/orchestrator/workflow/manager)\n",
    "* [Vowpal Wabbit Reinforcement Learning Framework](https://github.com/VowpalWabbit/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Open Source Bandit `ExperimentManager` Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/multi_armed_bandit_traffic_shift.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bandit model is implemented by the open source [**Bandit Experiment Manager**](./common/sagemaker_rl/orchestrator/workflow/manager/) provided with this example.  This This implementation continuously updates a Vowpal Wabbit reinforcement learning model using Amazon SageMaker, DynamoDB, Kinesis, and S3.\n",
    "\n",
    "The client application, a recommender system with a review service in our case, pings the SageMaker hosting endpoint that is serving the bandit model.  The application sends the an `event` with the `context` (ie. user, product, and review text) to the bandit model and receives a recommended action from the bandit model.  In our case, the action is 1 of 2 BERT models that we are testing.  The bandit model stores this event data (given context and recommended action) in S3 using Amazon Kinesis.  _Note:  The context makes this a \"contextual bandit\" and differentiates this implementation from a regular multi-armed bandit._\n",
    "\n",
    "The client application uses the recommended BERT model to classify the review text as star rating 1 through 5 and  compares the predicted star rating to the user-selected star rating.  If the BERT model correctly predicts the star rating of the review text (ie. matches the user-selected star rating), then the bandit model is rewarded with `reward=1`.  If the BERT model incorrectly classifies the star rating of the review text, the bandit model is not rewarded (`reward=0`).\n",
    "\n",
    "The client application stores the rewards data in S3 using Amazon Kinesis.  Periodically (ie. every 100 rewards), we incrementally train an updated bandit model with the latest the reward and event data.  This updated bandit model is evaluated against the current model using a holdout dataset of rewards and events.  If the bandit model accuracy is above a given threshold relative to the existing model, it is automatically deployed in a blue/green manner with no downtime.  SageMaker RL supports offline evaluation by performing counterfactual analysis (CFA).  By default, we apply [**doubly robust (DR) estimation**](https://arxiv.org/pdf/1103.4601.pdf) method. The bandit model tries to minimize the cost (`1 - reward`), so a smaller evaluation score indicates better bandit model performance.\n",
    "\n",
    "Unlike traditional A/B tests, the bandit model will learn the best BERT model (action) for a given context over time and begin to shift traffic to the best model.  Depending on the aggressiveness of the bandit model algorithm selected, the bandit model will continuously explore the under-performing models, but start to favor and exploit the over-performing models.  And unlike A/B tests, multi-armed bandits allow you to add a new action (ie. BERT model) dynamically throughout the life of the experiment.  When the bandit model sees the new BERT model, it will start sending traffic and exploring the accuracy of the new BERT model - alongside the existing BERT models in the experiment.\n",
    "\n",
    "#### Local Mode\n",
    "\n",
    "To facilitate experimentation, we provide a `local_mode` that runs the contextual bandit example using the SageMaker Notebook instance itself instead of the SageMaker training and hosting cluster instances.  The workflow remains the same in `local_mode`, but runs much faster for small datasets.  Hence, it is a useful tool for experimenting and debugging.  However, it will not scale to production use cases with high throughput and large datasets.  In `local_mode`, the training, evaluation, and hosting is done in the local [SageMaker Vowpal Wabbit Docker Container](https://github.com/aws/sagemaker-rl-container)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import sys\n",
    "import numpy as np\n",
    "import time\n",
    "import sagemaker\n",
    "\n",
    "sys.path.append('common')\n",
    "sys.path.append('common/sagemaker_rl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "\n",
    "The configuration for the bandits application can be specified in a `config.yaml` file as can be seen below. It configures the AWS resources needed. The DynamoDB tables are used to store metadata related to experiments, models and data joins. The `private_resource` specifices the SageMaker instance types and counts used for training, evaluation and hosting. The SageMaker container image is used for the bandits application. This config file also contains algorithm and SageMaker-specific setups.  Note that all the data generated and used for the bandits application will be stored in `s3://sagemaker-{REGION}-{AWS_ACCOUNT_ID}/{experiment_id}/`.\n",
    "\n",
    "Please make sure that the `num_arms` parameter in the config is equal to the number of actions in the client application (which is defined in the cell below).\n",
    "\n",
    "The Docker image is defined here:  https://github.com/aws/sagemaker-rl-container/blob/master/vw/docker/8.7.0/Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[94mresource\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m  \u001b[39;49;00m\u001b[94mshared_resource\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mresources_cf_stack_name\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mBanditsSharedResourceStack\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[37m# cloud formation stack\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mexperiment_db\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m      \u001b[39;49;00m\u001b[94mtable_name\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mBanditsExperimentTable\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[37m# Dynamo table for status of an experiment\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mmodel_db\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m      \u001b[39;49;00m\u001b[94mtable_name\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mBanditsModelTable\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[37m# Dynamo table for status of all models trained\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mjoin_db\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m      \u001b[39;49;00m\u001b[94mtable_name\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mBanditsJoinTable\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[37m# Dynamo table for status of all joining job for reward ingestion\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94miam_role\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m      \u001b[39;49;00m\u001b[94mrole_name\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mBanditsIAMRole\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m  \u001b[39;49;00m\u001b[94mprivate_resource\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mhosting_fleet\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m      \u001b[39;49;00m\u001b[94minstance_type\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mml.t2.medium\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m      \u001b[39;49;00m\u001b[94minstance_count\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m1\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mtraining_fleet\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m      \u001b[39;49;00m\u001b[94minstance_type\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mml.c5.4xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mevaluation_fleet\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m      \u001b[39;49;00m\u001b[94minstance_type\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mml.c5.4xlarge\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[94mimage\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m462105765813.dkr.ecr.{AWS_REGION}.amazonaws.com/sagemaker-rl-vw-container:vw-8.7.0-cpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[37m# Vowpal Wabbit container\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[94malgor\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[37m# Vowpal Wabbit algorithm parameters\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m  \u001b[39;49;00m\u001b[94malgorithms_parameters\u001b[39;49;00m:\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mexploration_policy\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mcover\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[37m# supports \"egreedy\", \"bag\", \"cover\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mepsilon\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m0.10\u001b[37m \u001b[39;49;00m\u001b[37m# percent to explore with egreedy exploration policy\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mnum_policies\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m3\u001b[37m \u001b[39;49;00m\u001b[37m# number of nested policies to create when using bag or cover exploration policy\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mnum_arms\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m2\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m    \u001b[39;49;00m\u001b[94mcfa_type\u001b[39;49;00m:\u001b[37m \u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mdr\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[37m \u001b[39;49;00m\u001b[37m# supports \"dr\", \"ips\"\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[94mlocal_mode\u001b[39;49;00m:\u001b[37m \u001b[39;49;00mfalse\u001b[37m \u001b[39;49;00m\u001b[37m# use local mode?\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[94msoft_deployment\u001b[39;49;00m:\u001b[37m \u001b[39;49;00mtrue\u001b[37m \u001b[39;49;00m\u001b[37m# use the same endpoint with updated model using a blue-green deployment?\u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n",
      "\u001b[37m \u001b[39;49;00m\u001b[37m\u001b[39;49;00m\n"
     ]
    }
   ],
   "source": [
    "!pygmentize 'config.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'config.yaml'\n",
    "with open(config_file, 'r') as yaml_file:\n",
    "    config = yaml.load(yaml_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Client Application (Environment)\n",
    "The client application simulates a live environment that uses the bandit model to recommend a BERT model to classify review text submitted by the application user. \n",
    "\n",
    "The logic of reward generation resides in the client application.  We simulate the online learning loop with feedback.  The data consists of 2 actions - 1 for each BERT model under test.  If the bandit model selects the right class, then the model is rewarded with `reward=1`.  Otherwise, the bandit model receives `reward=0`.\n",
    "\n",
    "The workflow of the client application is as follows:\n",
    "- Our client application picks sample review text at random, which is sent to the bandit model (SageMaker endpoint) to recommend an action (BERT model) to classify the review text into star rating 1 through 5.\n",
    "- The bandit model returns an action, an action probability, and an `event_id` for this prediction event.\n",
    "- Since the client application uses the Amazon Customer Reviews Dataset, we know the true star rating for the review text\n",
    "- The client application compares the predicted and true star rating and assigns a reward to the bandit model using Amazon Kinesis, S3, and DynamoDB.  (The `event_id` is used to join the event and reward data.)\n",
    "\n",
    "`event_id` is a unique identifier for each interaction. It is used to join inference data `<state, action, action_probability>` with the reward data. \n",
    "\n",
    "In a later cell of this notebook, we illustrate how the client application interacts with the bandit model endpoint and receives the recommended action (BERT model)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step bandits model development\n",
    "\n",
    "[**Bandit Experiment Manager**](./common/sagemaker_rl/orchestrator/workflow/manager/) is the top level class for all the Bandits/RL and continual learning workflows. Similar to the estimators in the [Sagemaker Python SDK](https://github.com/aws/sagemaker-python-sdk), `ExperimentManager` contains methods for training, deployment and evaluation. It keeps track of the job status and reflects current progress in the workflow.\n",
    "\n",
    "Start the application using the `ExperimentManager` class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = int(time.time())\n",
    "\n",
    "experiment_name = 'bandits-{}'.format(timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `ExperimentManager` will create a AWS CloudFormation Stack of additional resources needed for the Bandit experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:orchestrator.resource_manager:Creating a new CloudFormation stack for Shared Resources. You can always reuse this StackName in your other experiments\n",
      "INFO:orchestrator.resource_manager:[\n",
      "    {\n",
      "        \"ParameterKey\": \"IAMRoleName\",\n",
      "        \"ParameterValue\": \"BanditsIAMRole\",\n",
      "        \"UsePreviousValue\": true,\n",
      "        \"ResolvedValue\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"ParameterKey\": \"ExperimentDbName\",\n",
      "        \"ParameterValue\": \"BanditsExperimentTable\",\n",
      "        \"UsePreviousValue\": true,\n",
      "        \"ResolvedValue\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"ParameterKey\": \"ExperimentDbRCU\",\n",
      "        \"ParameterValue\": \"5\",\n",
      "        \"UsePreviousValue\": true,\n",
      "        \"ResolvedValue\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"ParameterKey\": \"ExperimentDbWCU\",\n",
      "        \"ParameterValue\": \"5\",\n",
      "        \"UsePreviousValue\": true,\n",
      "        \"ResolvedValue\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"ParameterKey\": \"ModelDbName\",\n",
      "        \"ParameterValue\": \"BanditsModelTable\",\n",
      "        \"UsePreviousValue\": true,\n",
      "        \"ResolvedValue\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"ParameterKey\": \"ModelDbRCU\",\n",
      "        \"ParameterValue\": \"5\",\n",
      "        \"UsePreviousValue\": true,\n",
      "        \"ResolvedValue\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"ParameterKey\": \"ModelDbWCU\",\n",
      "        \"ParameterValue\": \"5\",\n",
      "        \"UsePreviousValue\": true,\n",
      "        \"ResolvedValue\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"ParameterKey\": \"JoinDbName\",\n",
      "        \"ParameterValue\": \"BanditsJoinTable\",\n",
      "        \"UsePreviousValue\": true,\n",
      "        \"ResolvedValue\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"ParameterKey\": \"JoinDbRCU\",\n",
      "        \"ParameterValue\": \"5\",\n",
      "        \"UsePreviousValue\": true,\n",
      "        \"ResolvedValue\": \"string\"\n",
      "    },\n",
      "    {\n",
      "        \"ParameterKey\": \"JoinDbWCU\",\n",
      "        \"ParameterValue\": \"5\",\n",
      "        \"UsePreviousValue\": true,\n",
      "        \"ResolvedValue\": \"string\"\n",
      "    }\n",
      "]\n",
      "INFO:orchestrator.resource_manager:Creating CloudFormation Stack for shared resource!\n",
      "INFO:orchestrator.resource_manager:Waiting for stack to get to CREATE_COMPLETE state....\n"
     ]
    }
   ],
   "source": [
    "from orchestrator.workflow.manager.experiment_manager import ExperimentManager\n",
    "\n",
    "bandit_experiment_manager = ExperimentManager(config, experiment_id=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Client Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "class ClientApp():\n",
    "    def __init__(self, data, num_events, bandit_model, predictor_map):\n",
    "        self.bandit_model = bandit_model\n",
    "        self.predictor_map = predictor_map\n",
    "        \n",
    "        self.num_actions = 2\n",
    "\n",
    "        df_reviews = pd.read_csv(data, \n",
    "                                 delimiter='\\t', \n",
    "                                 quoting=csv.QUOTE_NONE,\n",
    "                                 compression='gzip')\n",
    "        df_scrubbed = df_reviews[['review_body', 'star_rating']].sample(n=num_events) # .query('star_rating == 1')\n",
    "        df_scrubbed = df_scrubbed.reset_index()\n",
    "        df_scrubbed.shape\n",
    "        np_reviews = df_scrubbed.to_numpy()\n",
    "\n",
    "        np_reviews = np.delete(np_reviews, 0, 1)\n",
    "        \n",
    "        # Last column is the label, the rest are the features (contexts)\n",
    "        self.labels = np_reviews[:, -1]\n",
    "        self.contexts = np_reviews[:, :-1].tolist()\n",
    "\n",
    "        self.optimal_rewards = [1]\n",
    "        self.rewards_tmp_buffer = []\n",
    "        self.joined_data_tmp_buffer = []\n",
    "        self.all_joined_data_buffer = []\n",
    "        \n",
    "        self.action_count = {}\n",
    "\n",
    "    def increment_action_count(self, action):\n",
    "        try:\n",
    "            action_count = self.action_count[action]\n",
    "        except:\n",
    "            self.action_count[action] = 0\n",
    "            action_count = 0\n",
    "            \n",
    "        self.action_count[action] = action_count + 1\n",
    "                \n",
    "    def choose_random_context(self):\n",
    "        context_index = np.random.choice(len(self.contexts))\n",
    "        context = self.contexts[context_index]\n",
    "        return context_index, context    \n",
    "\n",
    "    def clear_tmp_buffers(self):\n",
    "        self.rewards_tmp_buffer.clear()\n",
    "        self.joined_data_tmp_buffer.clear()\n",
    "\n",
    "    def get_reward(self, \n",
    "                   context_index, \n",
    "                   action, \n",
    "                   event_id, \n",
    "                   bandit_model_id, \n",
    "                   action_prob, \n",
    "                   sample_prob, \n",
    "                   local_mode):\n",
    "\n",
    "        context_to_predict = self.contexts[context_index][0]\n",
    "    \n",
    "        label = self.labels[context_index]\n",
    "        \n",
    "        predictor = self.predictor_map[action]\n",
    "\n",
    "        self.increment_action_count(action)\n",
    "        \n",
    "        # TensorFlow returns [str]\n",
    "        if (action == 1):\n",
    "            print('Predicting Class from Model 1: {}, Actual Class: {}'.format(predicted_class, label))\n",
    "            predicted_class = predictor.predict(context_to_predict)[0]\n",
    "            predicted_class\n",
    "            print('Predicted Class from Model 1: {}, Actual Class: {}'.format(predicted_class, label))\n",
    "\n",
    "        # PyTorch returns bytes\n",
    "        if (action == 2):\n",
    "            print('Predicting Class from Model 2: {}, Actual Class: {}'.format(predicted_class, label))\n",
    "            predicted_class = predictor.predict({\"review_body\": context_to_predict})\n",
    "            predicted_class = predicted_class# .decode('utf-8')\n",
    "            print('Predicted Class from Model 2: {}, Actual Class: {}'.format(predicted_class, label))\n",
    "            \n",
    "       # Calculate difference between predicted and actual label\n",
    "        if abs(int(predicted_class) - int(label)) == 0:\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        if local_mode:\n",
    "            json_blob = {\n",
    "                         \"reward\": reward,\n",
    "                         \"event_id\": event_id,\n",
    "                         \"action\": action,\n",
    "                         \"action_prob\": action_prob,\n",
    "                         \"model_id\": bandit_model_id,\n",
    "                         \"observation\": [context_index],\n",
    "                         \"sample_prob\": sample_prob\n",
    "                        }\n",
    "            \n",
    "            self.joined_data_tmp_buffer.append(json_blob)            \n",
    "        else:\n",
    "            json_blob = {\n",
    "                         \"reward\": reward, \n",
    "                         \"event_id\": event_id\n",
    "                        }\n",
    "            self.rewards_tmp_buffer.append(json_blob)\n",
    "        \n",
    "        return reward\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve model endpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r pipeline_endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model-from-registry-ep-1677906547\n"
     ]
    }
   ],
   "source": [
    "print(pipeline_endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints/model-from-registry-ep-1677906547\">SageMaker REST Endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST Endpoint</a></b>'.format(\n",
    "            region, pipeline_endpoint_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# _Wait Until the Endpoint is Deployed_\n",
    "_Note:  This will take a few minutes.  Please be patient._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 ms, sys: 3.13 ms, total: 16.9 ms\n",
      "Wall time: 165 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "waiter = sm.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=pipeline_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Wait Until the Endpoint ^^ Above ^^ is Deployed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from sagemaker import Predictor\n",
    "\n",
    "predictor1 = Predictor(\n",
    "    endpoint_name=pipeline_endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "predictor2 = Predictor(\n",
    "    endpoint_name=pipeline_endpoint_name,\n",
    "    sagemaker_session=sess,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orchestrator:Hosting endpoint is not ready yet. A deployment with model id 'None' is in state of 'None'. Please check later.\n"
     ]
    }
   ],
   "source": [
    "bandit_model = bandit_experiment_manager.predictor\n",
    "\n",
    "client_app = ClientApp(data='./data-tsv/amazon_reviews_us_Digital_Software_v1_00.tsv.gz',\n",
    "                       num_events=100,\n",
    "                       bandit_model=bandit_model,\n",
    "                       predictor_map={\n",
    "                         1: predictor1,\n",
    "                         2: predictor2\n",
    "                       })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Bandit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a new model with newly collected experiences, and host the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orchestrator:No joining job has been completed. Please check later.\n"
     ]
    },
    {
     "ename": "ClientError",
     "evalue": "An error occurred (ValidationException) when calling the Query operation: One or more parameter values were invalid: Condition parameter type does not match schema type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-8510985a5319>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbandit_experiment_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_next_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_data_s3_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbandit_experiment_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_joined_job_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/data-science-on-aws.gpt3/00_quickstart/common/sagemaker_rl/orchestrator/workflow/manager/experiment_manager.py\u001b[0m in \u001b[0;36mlast_joined_job_train_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    925\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlast_joined_job_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 927\u001b[0;31m         \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_db_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_join_job_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_joined_job_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    928\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_joined_train_data_s3_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/data-science-on-aws.gpt3/00_quickstart/common/sagemaker_rl/orchestrator/clients/ddb/join_db_client.py\u001b[0m in \u001b[0;36mget_join_job_record\u001b[0;34m(self, experiment_id, join_job_id)\u001b[0m\n\u001b[1;32m     19\u001b[0m         response = self.table_session.query(\n\u001b[1;32m     20\u001b[0m             \u001b[0mConsistentRead\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mKeyConditionExpression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"experiment_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"join_job_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_job_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         )\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Items\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/boto3/resources/factory.py\u001b[0m in \u001b[0;36mdo_action\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;31m# instance via ``self``.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0mdo_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'load'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/boto3/resources/action.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, parent, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         )\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Response: %r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_api_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    528\u001b[0m                 )\n\u001b[1;32m    529\u001b[0m             \u001b[0;31m# The \"self\" in this scope is referring to the BaseClient.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_api_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperation_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0m_api_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_operation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/botocore/client.py\u001b[0m in \u001b[0;36m_make_api_call\u001b[0;34m(self, operation_name, api_params)\u001b[0m\n\u001b[1;32m    958\u001b[0m             \u001b[0merror_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Code\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0merror_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 960\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0merror_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_response\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moperation_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    961\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    962\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mparsed_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mClientError\u001b[0m: An error occurred (ValidationException) when calling the Query operation: One or more parameter values were invalid: Condition parameter type does not match schema type"
     ]
    }
   ],
   "source": [
    "bandit_experiment_manager.train_next_model(input_data_s3_prefix=bandit_experiment_manager.last_joined_job_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy the Bandit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:orchestrator:No model has been trained. Please check later.\n",
      "WARNING:orchestrator:No model has been trained. Please check later.\n",
      "ERROR:orchestrator:Provided model id is None. Please provide valid model id.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying bandit model id None\n"
     ]
    }
   ],
   "source": [
    "print('Deploying bandit model id {}'.format(bandit_experiment_manager.last_trained_model_id))\n",
    "\n",
    "bandit_experiment_manager.deploy_model(model_id=bandit_experiment_manager.last_trained_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Experiment Status:  DEPLOYED\n",
    "`deploying_state`:  `SUCCEEDED`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'experiment_id': 'bandits-1677906224',\n",
       " 'training_workflow_metadata': {'next_model_to_train_id': None,\n",
       "  'last_trained_model_id': None,\n",
       "  'training_state': None},\n",
       " 'hosting_workflow_metadata': {'last_hosted_model_id': None,\n",
       "  'hosting_endpoint': None,\n",
       "  'hosting_state': None,\n",
       "  'next_model_to_host_id': None},\n",
       " 'joining_workflow_metadata': {'joining_state': None,\n",
       "  'next_join_job_id': None,\n",
       "  'last_joined_job_id': None},\n",
       " 'evaluation_workflow_metadata': {'evaluation_state': None,\n",
       "  'last_evaluation_job_id': None,\n",
       "  'next_evaluation_job_id': None}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bandit_experiment_manager._jsonify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuously Train, Evaluate, and Deploy Bandit Models\n",
    "The above cells explained the individual steps in the training workflow. To train a model to convergence, we will continually train the model based on data collected with client application interactions. We demonstrate the continual training and evaluation loop in a single cell below.\n",
    "\n",
    "_**Train and Evaluate**_:\n",
    "After every training cycle, we evaluate if the newly trained model (`last_trained_model_id`) would perform better than the one currently deployed (`last_hosted_model_id`) using a holdout evaluation dataset.  Details of the join, train, and evaluation steps are tracked in the `BanditsJoinTable` and `BanditsModelTable` DynamoDB tables.  When you have multiple experiments, you can compare them in the `BanditsExperimentTable` DynamoDB table.\n",
    "\n",
    "_**Deploy**_: If the new bandit model is better than the current bandit model (based on offline evaluation), we will automatically deploy the new bandit model using a blue-green deployment to avoid downtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ################################\n",
      "    # Incremental Training Loop 1\n",
      "    ################################\n",
      "    \n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_action'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-66d9d80642ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretrain_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcontext_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_random_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandit_model_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbandit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcontext_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         reward = client_app.get_reward(context_index=context_index, \n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_action'"
     ]
    }
   ],
   "source": [
    "do_evaluation = True\n",
    "total_loops = 5 # Increase for higher accuracy\n",
    "retrain_batch_size = 100 # Model will be trained after every `batch_size` number of data instances\n",
    "rewards_list = []\n",
    "event_list = []\n",
    "\n",
    "all_joined_train_data_s3_uri_list = []\n",
    "all_joined_eval_data_s3_uri_list = []\n",
    "\n",
    "local_mode = bandit_experiment_manager.local_mode\n",
    "\n",
    "start_time = time.time()\n",
    "for loop_no in range(total_loops):\n",
    "    print(f\"\"\"\n",
    "    ################################\n",
    "    # Incremental Training Loop {loop_no+1}\n",
    "    ################################\n",
    "    \"\"\")\n",
    "    \n",
    "    # Generate experiences and log them\n",
    "    for i in range(retrain_batch_size):\n",
    "        context_index, context = client_app.choose_random_context()\n",
    "        action, event_id, bandit_model_id, action_prob, sample_prob = bandit_model.get_action(obs=[context_index])\n",
    "\n",
    "        reward = client_app.get_reward(context_index=context_index, \n",
    "                                       action=action, \n",
    "                                       event_id=event_id, \n",
    "                                       bandit_model_id=bandit_model_id, \n",
    "                                       action_prob=action_prob, \n",
    "                                       sample_prob=sample_prob, \n",
    "                                       local_mode=local_mode)\n",
    "\n",
    "        rewards_list.append(reward)\n",
    "        \n",
    "    # Publish rewards sum for this batch to CloudWatch for monitoring \n",
    "    bandit_experiment_manager.cw_logger.publish_rewards_for_simulation(\n",
    "        bandit_experiment_manager.experiment_id,\n",
    "        sum(rewards_list[-retrain_batch_size:])/retrain_batch_size\n",
    "    )\n",
    "    \n",
    "    # Join the events and rewards data to use for the next bandit-model training job\n",
    "    # Use 90% as the training dataset and 10% as the the holdout evaluation dataset\n",
    "    if local_mode:        \n",
    "        bandit_experiment_manager.ingest_joined_data(client_app.joined_data_tmp_buffer,\n",
    "                                                     ratio=0.90)\n",
    "    else:\n",
    "        # Kinesis Firehose => S3 => Athena\n",
    "        print('Waiting for firehose to flush data to s3...')\n",
    "        time.sleep(60) \n",
    "        rewards_s3_prefix = bandit_experiment_manager.ingest_rewards(client_app.rewards_tmp_buffer)\n",
    "        bandit_experiment_manager.join(rewards_s3_prefix, ratio=0.90)\n",
    "            \n",
    "    # Train \n",
    "    bandit_experiment_manager.train_next_model(\n",
    "        input_data_s3_prefix=bandit_experiment_manager.last_joined_job_train_data)\n",
    "\n",
    "    all_joined_train_data_s3_uri_list.append(bandit_experiment_manager.last_joined_job_train_data)\n",
    "\n",
    "    # Evaluate and/or deploy the new bandit model\n",
    "    if do_evaluation:\n",
    "        bandit_experiment_manager.evaluate_model(\n",
    "            input_data_s3_prefix=bandit_experiment_manager.last_joined_job_eval_data,\n",
    "            evaluate_model_id=bandit_experiment_manager.last_trained_model_id)\n",
    "\n",
    "        eval_score_last_trained_model = bandit_experiment_manager.get_eval_score(\n",
    "            evaluate_model_id=bandit_experiment_manager.last_trained_model_id,\n",
    "            eval_data_path=bandit_experiment_manager.last_joined_job_eval_data)\n",
    "\n",
    "        bandit_experiment_manager.evaluate_model(\n",
    "            input_data_s3_prefix=bandit_experiment_manager.last_joined_job_eval_data,\n",
    "            evaluate_model_id=bandit_experiment_manager.last_hosted_model_id) \n",
    "\n",
    "        all_joined_eval_data_s3_uri_list.append(bandit_experiment_manager.last_joined_job_eval_data)\n",
    "    \n",
    "        # Eval score is a measure of `regret`, so a lower eval score is better\n",
    "        eval_score_last_hosted_model = bandit_experiment_manager.get_eval_score(\n",
    "            evaluate_model_id=bandit_experiment_manager.last_hosted_model_id, \n",
    "            eval_data_path=bandit_experiment_manager.last_joined_job_eval_data)\n",
    "    \n",
    "        print('New bandit model evaluation score {}'.format(eval_score_last_hosted_model))\n",
    "        print('Current bandit model evaluation score {}'.format(eval_score_last_trained_model))\n",
    "\n",
    "        if eval_score_last_trained_model <= eval_score_last_hosted_model:\n",
    "            print('Deploying new bandit model id {} in loop {}'.format(bandit_experiment_manager.last_trained_model_id, loop_no))\n",
    "            bandit_experiment_manager.deploy_model(model_id=bandit_experiment_manager.last_trained_model_id)\n",
    "        else:\n",
    "            print('Not deploying bandit model id {} in loop {}'.format(bandit_experiment_manager.last_trained_model_id, loop_no))\n",
    "    else:\n",
    "        # Just deploy the new bandit model without evaluating against previous model\n",
    "        print('Deploying new bandit model id {} in loop {}'.format(bandit_experiment_manager.last_trained_model_id, loop_no))\n",
    "        bandit_experiment_manager.deploy_model(model_id=bandit_experiment_manager.last_trained_model_id)\n",
    "    \n",
    "    client_app.clear_tmp_buffers()\n",
    "    \n",
    "print(f'Total time taken to complete {total_loops} loops: {time.time() - start_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Invocations of BERT Model 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-f07072e133c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total Invocations of BERT Model 1:  {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Total Invocations of BERT Model 2:  {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient_app\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "print('Total Invocations of Model 1:  {}'.format(client_app.action_count[1]))\n",
    "print('Total Invocations of Model 2:  {}'.format(client_app.action_count[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "\n",
    "cw = boto3.Session().client(service_name='cloudwatch', region_name=region)\n",
    "\n",
    "def get_invocation_metrics_for_endpoint_variant(endpoint_name,\n",
    "                                                namespace_name,\n",
    "                                                metric_name,\n",
    "                                                variant_name,\n",
    "                                                start_time,\n",
    "                                                end_time):\n",
    "    metrics = cw.get_metric_statistics(\n",
    "        Namespace=namespace_name,\n",
    "        MetricName=metric_name,\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=[\"Sum\"],\n",
    "        Dimensions=[\n",
    "            {\n",
    "                \"Name\": \"EndpointName\",\n",
    "                \"Value\": endpoint_name\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"VariantName\",\n",
    "                \"Value\": variant_name\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    if metrics['Datapoints']:\n",
    "        return pd.DataFrame(metrics[\"Datapoints\"])\\\n",
    "                .sort_values(\"Timestamp\")\\\n",
    "                .set_index(\"Timestamp\")\\\n",
    "                .drop(\"Unit\", axis=1)\\\n",
    "                .rename(columns={\"Sum\": variant_name})\n",
    "    else:\n",
    "        return pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather Model 1 Invocations Metrics\n",
    "_Please be patient.  This will take 1-2 minutes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_1_endpoint_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-c28173006e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m model_1_endpoint_invocations = get_invocation_metrics_for_endpoint_variant(\n\u001b[0;32m---> 11\u001b[0;31m                                     \u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_1_endpoint_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m                                     \u001b[0mnamespace_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'AWS/SageMaker'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                     \u001b[0mmetric_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Invocations'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_1_endpoint_name' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "time.sleep(75)\n",
    "\n",
    "start_time = start_time or datetime.now() - timedelta(minutes=60)\n",
    "end_time = datetime.now()\n",
    "        \n",
    "model_1_endpoint_invocations = get_invocation_metrics_for_endpoint_variant(\n",
    "                                    endpoint_name=model_1_endpoint_name,\n",
    "                                    namespace_name='AWS/SageMaker',                                   \n",
    "                                    metric_name='Invocations',\n",
    "                                    variant_name='AllTraffic',\n",
    "                                    start_time=start_time, \n",
    "                                    end_time=end_time)\n",
    "\n",
    "model_1_endpoint_invocations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather Model 2 Invocations Metrics\n",
    "_Please be patient.  This will take 1-2 minutes._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "time.sleep(75)\n",
    "\n",
    "start_time = start_time or datetime.now() - timedelta(minutes=60)\n",
    "end_time = datetime.now()\n",
    "        \n",
    "model_2_endpoint_invocations = get_invocation_metrics_for_endpoint_variant(\n",
    "                                    endpoint_name=model_2_endpoint_name,\n",
    "                                    namespace_name='AWS/SageMaker',                                   \n",
    "                                    metric_name='Invocations',\n",
    "                                    variant_name='AllTraffic',\n",
    "                                    start_time=start_time, \n",
    "                                    end_time=end_time)\n",
    "\n",
    "model_2_endpoint_invocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15, 10\n",
    "\n",
    "x1 = range(0, model_1_endpoint_invocations.size)\n",
    "y1 = model_1_endpoint_invocations['AllTraffic']\n",
    "plt.plot(x1, y1, label=\"BERT Model 1\")\n",
    "\n",
    "x1 = range(0, model_2_endpoint_invocations.size)\n",
    "y1 = model_2_endpoint_invocations['AllTraffic']\n",
    "plt.plot(x1, y1, label=\"BERT Model 2\")\n",
    "\n",
    "plt.legend(loc=0, prop={'size': 20})\n",
    "plt.xlabel('Time (Minutes)')\n",
    "plt.ylabel('Number of Invocations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the Invocation Metrics for the BERT Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "    \n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#metricsV2:namespace=AWS/SageMaker;dimensions=EndpointName,VariantName;search={}\">Model 1 SageMaker REST Endpoint</a></b>'.format(region, model_1_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#metricsV2:namespace=AWS/SageMaker;dimensions=EndpointName,VariantName;search={}\">Model 2 SageMaker REST Endpoint</a></b>'.format(region, model_2_endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Bandit Action Probabilities\n",
    "This is the probability that the bandit model will choose a particular BERT model (action)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15, 10\n",
    "\n",
    "x1 = all_joined_data_df.query('action==1').index\n",
    "y1 = all_joined_data_df.query('action==1').action_prob\n",
    "plt.scatter(x1, y1, label=\"Model 1\")\n",
    "\n",
    "x2 = all_joined_data_df.query('action==2').index\n",
    "y2 = all_joined_data_df.query('action==2').action_prob\n",
    "plt.scatter(x2, y2, label=\"Model 2\")\n",
    "\n",
    "plt.legend(loc=3, prop={'size': 20})\n",
    "plt.xlabel('Bandit Model Training Instances')\n",
    "plt.ylabel('Action Probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Mean action probability for Model 1: {}'.format(all_joined_data_df.query('action==1')['action_prob'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Mean action probability for Model 2: {}'.format(all_joined_data_df.query('action==2')['action_prob'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Bandit Sample Probabilities\n",
    "Despite the action probability, we sample from all actions (BERT models).  Below is the sample probability for the chosen BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = 15, 10\n",
    "\n",
    "x1 = all_joined_data_df.query('action==1').index\n",
    "y1 = all_joined_data_df.query('action==1').sample_prob\n",
    "plt.scatter(x1, y1, label=\"Model 1\")\n",
    "\n",
    "x2 = all_joined_data_df.query('action==2').index\n",
    "y2 = all_joined_data_df.query('action==2').sample_prob\n",
    "plt.scatter(x2, y2, label=\"Model 2\")\n",
    "\n",
    "plt.legend(loc=0, prop={'size': 20})\n",
    "plt.xlabel('Bandit Model Training Instances')\n",
    "plt.ylabel('Sample Probability')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Mean sample probability for Model 1: {}'.format(all_joined_data_df.query('action==1')['sample_prob'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Mean sample probability for Model 2: {}'.format(all_joined_data_df.query('action==2')['sample_prob'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Bandit Rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can visualize the bandit-model training performance by plotting the rolling mean reward across client interactions.\n",
    "\n",
    "Here rolling mean reward is calculated on the last `rolling_window` number of data instances, where each data instance corresponds to a single client interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window = 100\n",
    "\n",
    "rcParams['figure.figsize'] = 15, 10\n",
    "lwd = 5\n",
    "cmap = plt.get_cmap('tab20')\n",
    "colors=plt.cm.tab20(np.linspace(0, 1, 20))\n",
    "\n",
    "rewards_df = pd.DataFrame(rewards_list, columns=['bandit']).rolling(rolling_window).mean()\n",
    "#rewards_df['perfect'] = sum(client_app.optimal_rewards) / len(client_app.optimal_rewards)\n",
    "\n",
    "rewards_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_df.plot(y=['bandit'],  #, 'perfect'], \n",
    "                linewidth=lwd)\n",
    "plt.legend(loc=4, prop={'size': 20})\n",
    "plt.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.yticks([0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 1.00])\n",
    "plt.xticks([100, 200, 300, 400, 500, 600, 700, 800, 900, 1000])\n",
    "\n",
    "plt.xlabel('Training Instances (Model is Updated Every %s Instances)' % retrain_batch_size, size=20)\n",
    "plt.ylabel('Rolling {} Mean Reward'.format(rolling_window), size=30)\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_df['bandit'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitor the Bandit Model in CloudWatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from markdown_helper import *\n",
    "from IPython.display import Markdown\n",
    "\n",
    "display(Markdown(bandit_experiment_manager.get_cloudwatch_dashboard_details()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   }
  ],
  "hide_input": false,
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "550.4px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
